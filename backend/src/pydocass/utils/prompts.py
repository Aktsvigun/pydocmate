USER_PROMPT = """
Input code:
```
{code}
```

Json schema:
```
{json_schema}
```
""".strip()

MESSAGES_ARGUMENTS_ANNOTATION = [
    {
        "role": "system",
        "content": "Act as an experienced Python specialist.\n\nPlease annotate the arguments of each function, class, and method (of every class) from the input code, following the provided json schema. If you are not sure in how to annotate the argument, use the `Any` class from the `typing` package. For generic / container types, always annotate their type parameter. If you are not sure about how to annotate the type parameter, use the `Any` class as well. If you see apparent mistakes in existing annotations and you are sure they are erroneous, correct them.",
    },
    {
        "role": "user",
        "content": "Input code:\n```\nfrom abc import ABC, abstractmethod\nimport json\nfrom pathlib import Path\nfrom omegaconf import DictConfig\n\nfrom .utils import ModelOutput\n\nclass TrainingOutput:\n    score: float\n    num_epochs: int = 10\n    num_steps = 100\n    params_norm_divergence = 0.\n    output: ModelOutput = ModelOutput()\n\nclass BaseLabeler(ABC):\n    def __init__(\n    self, output_column_name: str = \"output\", budget=1_000_000):\n        self.output_column_name = output_column_name\n        self.budget = budget if budget is not None else 1e15\n\n    @staticmethod\n    def load_from_json(json_path\n    ):\n        with open(json_path) as f:\n            data = json.load(f)\n        return BaseLabeler(**data)\n\n    @property\n    def is_out_of_budget(self):\n        return self.budget < 0\n\n    def add_budget(self, increase: int):\n        self.budget += increase\n\n    @abstractmethod\n    def __call__(self, dataset: Dataset) -> Dataset:\n        pass\n\ndef get_initial_labeled_data(\n    config, unlabeled_data: Dataset, labeller\n):\n    \"\"\"Docstring is required for this function\n    \"\"\"\n    random_data_to_label_size = max(\n        config.al.init_query_size, config.data.few_shot.count\n    )\n    random_data_to_label = unlabeled_data.train_test_split(\n        train_size=random_data_to_label_size, shuffle=True, seed=config.seed\n    )[\"train\"]\n\n    labeled_data = labeller(random_data_to_label)\n    if labeller.is_out_of_budget:\n        logging.info(\"Labeler ran out of budget when labeling the initial query.\")\n\n    return labeled_data, labeled_data[\"id\"]\n```\n\nJson schema:\n```\n{'$defs': {'ClassBaselabelerMethodAdd_Budget': {'properties': {'increase': {'increase': {'default': 'int', 'description': 'Annotation of the argument: `increase` with current annotation: `int`.'}, 'title': 'Increase', 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['increase', 'returns'], 'title': 'ClassBaselabelerMethodAdd_Budget', 'type': 'object'}, 'ClassBaselabelerMethodIs_Out_Of_Budget': {'properties': {'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['returns'], 'title': 'ClassBaselabelerMethodIs_Out_Of_Budget', 'type': 'object'}, 'ClassBaselabelerMethodLoad_From_Json': {'properties': {'json_path': {'json_path': {'description': 'Annotation of the argument: `json_path`.'}, 'title': 'Json Path', 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['json_path', 'returns'], 'title': 'ClassBaselabelerMethodLoad_From_Json', 'type': 'object'}, 'ClassBaselabelerMethod__Call__': {'properties': {'dataset': {'dataset': {'default': 'Dataset', 'description': 'Annotation of the argument: `dataset` with current annotation: `Dataset`.'}, 'title': 'Dataset', 'type': 'string'}, 'returns': {'default': 'Dataset', 'description': 'Return type annotation. This is the type hint that appears after the `->`. Current annotation: `Dataset`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['dataset'], 'title': 'ClassBaselabelerMethod__Call__', 'type': 'object'}, 'ClassBaselabelerMethod__Init__': {'properties': {'output_column_name': {'budget': {'description': 'Annotation of the argument: `budget` with default value: `1000000`.'}, 'output_column_name': {'default': 'str', 'description': \"Annotation of the argument: `output_column_name` with default value: `'output'`, and current annotation: `str`.\"}, 'title': 'Output Column Name', 'type': 'string'}, 'budget': {'budget': {'description': 'Annotation of the argument: `budget` with default value: `1000000`.'}, 'output_column_name': {'default': 'str', 'description': \"Annotation of the argument: `output_column_name` with default value: `'output'`, and current annotation: `str`.\"}, 'title': 'Budget', 'type': 'string'}}, 'required': ['output_column_name', 'budget'], 'title': 'ClassBaselabelerMethod__Init__', 'type': 'object'}, 'ClassTrainingoutput': {'properties': {'score': {'num_epochs': {'default': 'int', 'description': 'Annotation of the argument: `num_epochs` with default value: `10`, and current annotation: `int`.'}, 'num_steps': {'description': 'Annotation of the argument: `num_steps` with default value: `100`.'}, 'output': {'default': 'ModelOutput', 'description': 'Annotation of the argument: `output` with default value: `ModelOutput()`, and current annotation: `ModelOutput`.'}, 'params_norm_divergence': {'description': 'Annotation of the argument: `params_norm_divergence` with default value: `0.0`.'}, 'score': {'default': 'float', 'description': 'Annotation of the argument: `score` with current annotation: `float`.'}, 'title': 'Score', 'type': 'string'}, 'num_epochs': {'num_epochs': {'default': 'int', 'description': 'Annotation of the argument: `num_epochs` with default value: `10`, and current annotation: `int`.'}, 'num_steps': {'description': 'Annotation of the argument: `num_steps` with default value: `100`.'}, 'output': {'default': 'ModelOutput', 'description': 'Annotation of the argument: `output` with default value: `ModelOutput()`, and current annotation: `ModelOutput`.'}, 'params_norm_divergence': {'description': 'Annotation of the argument: `params_norm_divergence` with default value: `0.0`.'}, 'score': {'default': 'float', 'description': 'Annotation of the argument: `score` with current annotation: `float`.'}, 'title': 'Num Epochs', 'type': 'string'}, 'num_steps': {'num_epochs': {'default': 'int', 'description': 'Annotation of the argument: `num_epochs` with default value: `10`, and current annotation: `int`.'}, 'num_steps': {'description': 'Annotation of the argument: `num_steps` with default value: `100`.'}, 'output': {'default': 'ModelOutput', 'description': 'Annotation of the argument: `output` with default value: `ModelOutput()`, and current annotation: `ModelOutput`.'}, 'params_norm_divergence': {'description': 'Annotation of the argument: `params_norm_divergence` with default value: `0.0`.'}, 'score': {'default': 'float', 'description': 'Annotation of the argument: `score` with current annotation: `float`.'}, 'title': 'Num Steps', 'type': 'string'}, 'params_norm_divergence': {'num_epochs': {'default': 'int', 'description': 'Annotation of the argument: `num_epochs` with default value: `10`, and current annotation: `int`.'}, 'num_steps': {'description': 'Annotation of the argument: `num_steps` with default value: `100`.'}, 'output': {'default': 'ModelOutput', 'description': 'Annotation of the argument: `output` with default value: `ModelOutput()`, and current annotation: `ModelOutput`.'}, 'params_norm_divergence': {'description': 'Annotation of the argument: `params_norm_divergence` with default value: `0.0`.'}, 'score': {'default': 'float', 'description': 'Annotation of the argument: `score` with current annotation: `float`.'}, 'title': 'Params Norm Divergence', 'type': 'string'}, 'output': {'num_epochs': {'default': 'int', 'description': 'Annotation of the argument: `num_epochs` with default value: `10`, and current annotation: `int`.'}, 'num_steps': {'description': 'Annotation of the argument: `num_steps` with default value: `100`.'}, 'output': {'default': 'ModelOutput', 'description': 'Annotation of the argument: `output` with default value: `ModelOutput()`, and current annotation: `ModelOutput`.'}, 'params_norm_divergence': {'description': 'Annotation of the argument: `params_norm_divergence` with default value: `0.0`.'}, 'score': {'default': 'float', 'description': 'Annotation of the argument: `score` with current annotation: `float`.'}, 'title': 'Output', 'type': 'string'}}, 'required': ['score', 'num_epochs', 'num_steps', 'params_norm_divergence', 'output'], 'title': 'ClassTrainingoutput', 'type': 'object'}, 'FunctionGet_Initial_Labeled_Data': {'properties': {'config': {'config': {'description': 'Annotation of the argument: `config`.'}, 'labeller': {'description': 'Annotation of the argument: `labeller`.'}, 'title': 'Config', 'type': 'string', 'unlabeled_data': {'default': 'Dataset', 'description': 'Annotation of the argument: `unlabeled_data` with current annotation: `Dataset`.'}}, 'unlabeled_data': {'config': {'description': 'Annotation of the argument: `config`.'}, 'labeller': {'description': 'Annotation of the argument: `labeller`.'}, 'title': 'Unlabeled Data', 'type': 'string', 'unlabeled_data': {'default': 'Dataset', 'description': 'Annotation of the argument: `unlabeled_data` with current annotation: `Dataset`.'}}, 'labeller': {'config': {'description': 'Annotation of the argument: `config`.'}, 'labeller': {'description': 'Annotation of the argument: `labeller`.'}, 'title': 'Labeller', 'type': 'string', 'unlabeled_data': {'default': 'Dataset', 'description': 'Annotation of the argument: `unlabeled_data` with current annotation: `Dataset`.'}}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['config', 'unlabeled_data', 'labeller', 'returns'], 'title': 'FunctionGet_Initial_Labeled_Data', 'type': 'object'}}, 'properties': {'ClassTrainingoutput': {'$ref': '#/$defs/ClassTrainingoutput'}, 'ClassBaselabelerMethod__Init__': {'$ref': '#/$defs/ClassBaselabelerMethod__Init__'}, 'ClassBaselabelerMethodLoad_From_Json': {'$ref': '#/$defs/ClassBaselabelerMethodLoad_From_Json'}, 'ClassBaselabelerMethodIs_Out_Of_Budget': {'$ref': '#/$defs/ClassBaselabelerMethodIs_Out_Of_Budget'}, 'ClassBaselabelerMethodAdd_Budget': {'$ref': '#/$defs/ClassBaselabelerMethodAdd_Budget'}, 'ClassBaselabelerMethod__Call__': {'$ref': '#/$defs/ClassBaselabelerMethod__Call__'}, 'FunctionGet_Initial_Labeled_Data': {'$ref': '#/$defs/FunctionGet_Initial_Labeled_Data'}}, 'required': ['ClassTrainingoutput', 'ClassBaselabelerMethod__Init__', 'ClassBaselabelerMethodLoad_From_Json', 'ClassBaselabelerMethodIs_Out_Of_Budget', 'ClassBaselabelerMethodAdd_Budget', 'ClassBaselabelerMethod__Call__', 'FunctionGet_Initial_Labeled_Data'], 'title': 'ArgumentsModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '{"ClassTrainingoutput": {"score": "float", "num_epochs": "int", "num_steps": "int", "params_norm_divergence": "float", "output": "ModelOutput"}, "ClassBaselabelerMethod__Init__": {"output_column_name": "str", "budget": "int"}, "ClassBaselabelerMethodLoad_From_Json": {"json_path": "str | Path", "returns": "BaseLabeler"}, "ClassBaselabelerMethodIs_Out_Of_Budget": {"returns": "bool"}, "ClassBaselabelerMethodAdd_Budget": {"increase": "int", "returns": "None"}, "ClassBaselabelerMethod__Call__": {"dataset": "Dataset", "returns": "Dataset"}, "FunctionGet_Initial_Labeled_Data": {"config": "DictConfig", "unlabeled_data": "Dataset", "labeller": "BaseLabeler", "returns": "tuple[Dataset, Any]"}}',
    },
    {
        "role": "user",
        "content": "Input code:\n```\nfrom math import sqrt\nfrom random import randint\n\ndef noisy_addition(x, y):\n    return x + y + randint(1, 10)\n\ndef noisy_multiplication(x, y):\n    return x * y * (random() + 1)\n\ndef process_number(value, factor) -> dict:\n    result = {}\n\n    result['original'] = value\n    result['sqrt'] = sqrt(value)\n    result['added'] = noisy_addition(value, factor)\n    result['multiplied'] = noisy_multiplication(value, factor)\n\n    return result\n```\n\nJson schema:\n```\n{'$defs': {'FunctionNoisy_Addition': {'properties': {'x': {'title': 'X', 'type': 'string', 'x': {'description': 'Annotation of the argument: `x`.'}, 'y': {'description': 'Annotation of the argument: `y`.'}}, 'y': {'title': 'Y', 'type': 'string', 'x': {'description': 'Annotation of the argument: `x`.'}, 'y': {'description': 'Annotation of the argument: `y`.'}}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['x', 'y', 'returns'], 'title': 'FunctionNoisy_Addition', 'type': 'object'}, 'FunctionNoisy_Multiplication': {'properties': {'x': {'title': 'X', 'type': 'string', 'x': {'description': 'Annotation of the argument: `x`.'}, 'y': {'description': 'Annotation of the argument: `y`.'}}, 'y': {'title': 'Y', 'type': 'string', 'x': {'description': 'Annotation of the argument: `x`.'}, 'y': {'description': 'Annotation of the argument: `y`.'}}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['x', 'y', 'returns'], 'title': 'FunctionNoisy_Multiplication', 'type': 'object'}, 'FunctionProcess_Number': {'properties': {'value': {'factor': {'description': 'Annotation of the argument: `factor`.'}, 'title': 'Value', 'type': 'string', 'value': {'description': 'Annotation of the argument: `value`.'}}, 'factor': {'factor': {'description': 'Annotation of the argument: `factor`.'}, 'title': 'Factor', 'type': 'string', 'value': {'description': 'Annotation of the argument: `value`.'}}, 'returns': {'default': 'dict', 'description': 'Return type annotation. This is the type hint that appears after the `->`. Current annotation: `dict`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['value', 'factor'], 'title': 'FunctionProcess_Number', 'type': 'object'}}, 'properties': {'FunctionNoisy_Addition': {'$ref': '#/$defs/FunctionNoisy_Addition'}, 'FunctionNoisy_Multiplication': {'$ref': '#/$defs/FunctionNoisy_Multiplication'}, 'FunctionProcess_Number': {'$ref': '#/$defs/FunctionProcess_Number'}}, 'required': ['FunctionNoisy_Addition', 'FunctionNoisy_Multiplication', 'FunctionProcess_Number'], 'title': 'ArgumentsModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '{"FunctionNoisy_Addition": {"x": "int | float", "y": "int | float", "returns": "int | float"}, "FunctionNoisy_Multiplication": {"x": "int | float", "y": "int | float", "returns": "float"}, "FunctionProcess_Number": {"value": "int | float", "factor": "int | float", "returns": "dict[str, int | float]"}}',
    },
    {
        "role": "user",
        "content": "Input code:\n```\nInput code:\n```\nimport openai\nimport os\nimport logging\nimport diskcache as dc\nimport re\nfrom pathlib import Path\n\n\nlog = logging.getLogger()\n\ndef clean_text(raw_text: str):\n    cleaned = re.sub(r'\\W+', r' ', raw_text)\n    return cleaned.lower()\n\ndef extract_keywords(text, tokenizer, make_lower):\n    tokens = text.tokenize(tokenizer, make_lower)\n    return [token for token in tokens if token.is_string()]\n\ndef tokenize_text(cleaned_text):\n    return cleaned_text.split()\n\n\nclass OpenAIChat:\n    \"\"\" Allows for the implementation of a singleton class to chat with OpenAI model for dataset marking.\n    \"\"\"\n    openai_model = \"gpt-4o\"\n    cache_path = Path(os.path.expanduser(\"~\")) / \".cache\"\n\n    def __post_init__(self):\n        api_key = os.environ.get(\"OPENAI_API_KEY\", None)\n        if api_key is not None:\n            openai.api_key = api_key\n\n        self.cache_path = self.cache_path / \"openai_chat_cache.diskcache\"\n        if not os.path.exists(cache_path):\n            os.makedirs(cache_path)\n\n    def ask(self, message):\n        \"\"\"\n        Parameters\n        ----------\n        message: str\n            the message to ask.\n        \"\"\"\n        cache_settings = dc.DEFAULT_SETTINGS.copy()\n        openai_responses = dc.Cache(self.cache_path, **cache_settings)\n\n        if (self.openai_model, message) in openai_responses:\n            reply = openai_responses[(self.openai_model, message)]\n\n        else:\n            # Ask openai\n            messages = [\n                {\"role\": \"system\", \"content\": \"You are an intelligent assistant.\"},\n                {\"role\": \"user\", \"content\": message},\n            ]\n            chat = self._send_request(messages)\n            reply = chat.choices[0].message.content\n\n            openai_responses[(self.openai_model, message)] = reply\n            openai_responses.close()\n\n        return reply\n\n    def _send_request(self, messages):\n        return openai.OpenAI().chat.completions.create(\n            model=self.openai_model,\n            messages=messages,\n            temperature=0,  # for deterministic outputs\n        )\n```\n\nJson schema:\n```\n{'$defs': {'ClassOpenaichat': {'properties': {'openai_model': {'cache_path': {'description': \"Annotation of the argument: `cache_path` with default value: `Path(os.path.expanduser('~')) / '.cache'`.\"}, 'openai_model': {'description': \"Annotation of the argument: `openai_model` with default value: `'gpt-4o'`.\"}, 'title': 'Openai Model', 'type': 'string'}, 'cache_path': {'cache_path': {'description': \"Annotation of the argument: `cache_path` with default value: `Path(os.path.expanduser('~')) / '.cache'`.\"}, 'openai_model': {'description': \"Annotation of the argument: `openai_model` with default value: `'gpt-4o'`.\"}, 'title': 'Cache Path', 'type': 'string'}}, 'required': ['openai_model', 'cache_path'], 'title': 'ClassOpenaichat', 'type': 'object'}, 'ClassOpenaichatMethodAsk': {'properties': {'message': {'message': {'description': 'Annotation of the argument: `message`.'}, 'title': 'Message', 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['message', 'returns'], 'title': 'ClassOpenaichatMethodAsk', 'type': 'object'}, 'ClassOpenaichatMethod_Send_Request': {'properties': {'messages': {'messages': {'description': 'Annotation of the argument: `messages`.'}, 'title': 'Messages', 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['messages', 'returns'], 'title': 'ClassOpenaichatMethod_Send_Request', 'type': 'object'}, 'FunctionClean_Text': {'properties': {'raw_text': {'raw_text': {'default': 'str', 'description': 'Annotation of the argument: `raw_text` with current annotation: `str`.'}, 'title': 'Raw Text', 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['raw_text', 'returns'], 'title': 'FunctionClean_Text', 'type': 'object'}, 'FunctionExtract_Keywords': {'properties': {'text': {'make_lower': {'description': 'Annotation of the argument: `make_lower`.'}, 'text': {'description': 'Annotation of the argument: `text`.'}, 'title': 'Text', 'tokenizer': {'description': 'Annotation of the argument: `tokenizer`.'}, 'type': 'string'}, 'tokenizer': {'make_lower': {'description': 'Annotation of the argument: `make_lower`.'}, 'text': {'description': 'Annotation of the argument: `text`.'}, 'title': 'Tokenizer', 'tokenizer': {'description': 'Annotation of the argument: `tokenizer`.'}, 'type': 'string'}, 'make_lower': {'make_lower': {'description': 'Annotation of the argument: `make_lower`.'}, 'text': {'description': 'Annotation of the argument: `text`.'}, 'title': 'Make Lower', 'tokenizer': {'description': 'Annotation of the argument: `tokenizer`.'}, 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['text', 'tokenizer', 'make_lower', 'returns'], 'title': 'FunctionExtract_Keywords', 'type': 'object'}, 'FunctionTokenize_Text': {'properties': {'cleaned_text': {'cleaned_text': {'description': 'Annotation of the argument: `cleaned_text`.'}, 'title': 'Cleaned Text', 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['cleaned_text', 'returns'], 'title': 'FunctionTokenize_Text', 'type': 'object'}}, 'properties': {'FunctionClean_Text': {'$ref': '#/$defs/FunctionClean_Text'}, 'FunctionExtract_Keywords': {'$ref': '#/$defs/FunctionExtract_Keywords'}, 'FunctionTokenize_Text': {'$ref': '#/$defs/FunctionTokenize_Text'}, 'ClassOpenaichat': {'$ref': '#/$defs/ClassOpenaichat'}, 'ClassOpenaichatMethodAsk': {'$ref': '#/$defs/ClassOpenaichatMethodAsk'}, 'ClassOpenaichatMethod_Send_Request': {'$ref': '#/$defs/ClassOpenaichatMethod_Send_Request'}}, 'required': ['FunctionClean_Text', 'FunctionExtract_Keywords', 'FunctionTokenize_Text', 'ClassOpenaichat', 'ClassOpenaichatMethodAsk', 'ClassOpenaichatMethod_Send_Request'], 'title': 'ArgumentsModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '{"FunctionClean_Text": {"raw_text": "str", "returns": "str"}, "FunctionExtract_Keywords": {"text": "Any", "tokenizer": "Any", "make_lower": "bool", "returns": "list[str]"}, "FunctionTokenize_Text": {"cleaned_text": "str", "returns": "list[str]"}, "ClassOpenaichat": {"openai_model": "str", "cache_path": "Path"}, "ClassOpenaichatMethodAsk": {"message": "str", "returns": "str"}, "ClassOpenaichatMethod_Send_Request": {"messages": "list[dict[str, str]]", "returns": "Any"}}',
    },
    {
        "role": "user",
        "content": "import asyncio\nimport base64\nfrom typing import Literal\n\nfrom openai import Client\n\nfrom ..utils.validate_llm_kwargs import validate_llm_kwargs\n\n\n# Function to encode the image to base64\ndef _encode_image_to_base64(image_path: str) -> str:\n    with open(image_path, \"rb\") as image_file:\n        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n\n\n# Function to call GPT-4o API with the base64 image and a question\nasync def _acall_model(\n    client: Client,\n    base64_image: str,\n    input_type: Literal[\"png\", \"jpg\", \"jpeg\", \"gif\", \"webp\"],\n    prompt: str,\n    model_checkpoint: str = \"gpt-4o-2024-08-06\",\n    **llm_kwargs,\n):\n    llm_kwargs = validate_llm_kwargs(llm_kwargs)\n    response = client.chat.completions.create(\n        model=model_checkpoint,  # Use GPT-4o model identifier\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"text\", \"text\": prompt},\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\n                            \"url\": f\"data:image/{input_type};base64,{base64_image}\",\n                            \"detail\": \"high\",  # Adjust to \"low\" for a less detailed analysis\n                        },\n                    },\n                ],\n            }\n        ],\n        **llm_kwargs,\n    )\n    # Return the response from the model\n    return response.choices[0].message.content.strip()\n\n\nasync def _process_page(\n    client, base64_page, input_type, prompt, model_checkpoint, page_num\n):\n    result = f\"\n\n=== Page {page_num} ===\n\n\"\n    result += await _acall_model(\n        client, base64_page, input_type, prompt, model_checkpoint\n    )\n    return result, page_num\n\n\nasync def _process_all_pages(\n    client, base64_pages, input_type, prompt, model_checkpoint\n):\n    tasks = [\n        _process_page(client, page, input_type, prompt, model_checkpoint, i)\n        for i, page in enumerate(base64_pages, 1)\n    ]\n\n    results = await asyncio.gather(*tasks)\n    sorted_results = sorted(results, key=lambda x: x[1])\n    return \"\".join(result[0] for result in sorted_results)\n```\n\nJson schema:\n```\n{'$defs': {'Function_Acall_Model': {'properties': {'client': {'base64_image': {'default': 'str', 'description': 'Annotation of the argument: `base64_image` with current annotation: `str`.'}, 'client': {'default': 'Client', 'description': 'Annotation of the argument: `client` with current annotation: `Client`.'}, 'input_type': {'default': \"Literal['png', 'jpg', 'jpeg', 'gif', 'webp']\", 'description': \"Annotation of the argument: `input_type` with current annotation: `Literal['png', 'jpg', 'jpeg', 'gif', 'webp']`.\"}, 'model_checkpoint': {'default': 'str', 'description': \"Annotation of the argument: `model_checkpoint` with default value: `'gpt-4o-2024-08-06'`, and current annotation: `str`.\"}, 'prompt': {'default': 'str', 'description': 'Annotation of the argument: `prompt` with current annotation: `str`.'}, 'title': 'Client', 'type': 'string'}, 'base64_image': {'base64_image': {'default': 'str', 'description': 'Annotation of the argument: `base64_image` with current annotation: `str`.'}, 'client': {'default': 'Client', 'description': 'Annotation of the argument: `client` with current annotation: `Client`.'}, 'input_type': {'default': \"Literal['png', 'jpg', 'jpeg', 'gif', 'webp']\", 'description': \"Annotation of the argument: `input_type` with current annotation: `Literal['png', 'jpg', 'jpeg', 'gif', 'webp']`.\"}, 'model_checkpoint': {'default': 'str', 'description': \"Annotation of the argument: `model_checkpoint` with default value: `'gpt-4o-2024-08-06'`, and current annotation: `str`.\"}, 'prompt': {'default': 'str', 'description': 'Annotation of the argument: `prompt` with current annotation: `str`.'}, 'title': 'Base64 Image', 'type': 'string'}, 'input_type': {'base64_image': {'default': 'str', 'description': 'Annotation of the argument: `base64_image` with current annotation: `str`.'}, 'client': {'default': 'Client', 'description': 'Annotation of the argument: `client` with current annotation: `Client`.'}, 'input_type': {'default': \"Literal['png', 'jpg', 'jpeg', 'gif', 'webp']\", 'description': \"Annotation of the argument: `input_type` with current annotation: `Literal['png', 'jpg', 'jpeg', 'gif', 'webp']`.\"}, 'model_checkpoint': {'default': 'str', 'description': \"Annotation of the argument: `model_checkpoint` with default value: `'gpt-4o-2024-08-06'`, and current annotation: `str`.\"}, 'prompt': {'default': 'str', 'description': 'Annotation of the argument: `prompt` with current annotation: `str`.'}, 'title': 'Input Type', 'type': 'string'}, 'prompt': {'base64_image': {'default': 'str', 'description': 'Annotation of the argument: `base64_image` with current annotation: `str`.'}, 'client': {'default': 'Client', 'description': 'Annotation of the argument: `client` with current annotation: `Client`.'}, 'input_type': {'default': \"Literal['png', 'jpg', 'jpeg', 'gif', 'webp']\", 'description': \"Annotation of the argument: `input_type` with current annotation: `Literal['png', 'jpg', 'jpeg', 'gif', 'webp']`.\"}, 'model_checkpoint': {'default': 'str', 'description': \"Annotation of the argument: `model_checkpoint` with default value: `'gpt-4o-2024-08-06'`, and current annotation: `str`.\"}, 'prompt': {'default': 'str', 'description': 'Annotation of the argument: `prompt` with current annotation: `str`.'}, 'title': 'Prompt', 'type': 'string'}, 'model_checkpoint': {'base64_image': {'default': 'str', 'description': 'Annotation of the argument: `base64_image` with current annotation: `str`.'}, 'client': {'default': 'Client', 'description': 'Annotation of the argument: `client` with current annotation: `Client`.'}, 'input_type': {'default': \"Literal['png', 'jpg', 'jpeg', 'gif', 'webp']\", 'description': \"Annotation of the argument: `input_type` with current annotation: `Literal['png', 'jpg', 'jpeg', 'gif', 'webp']`.\"}, 'model_checkpoint': {'default': 'str', 'description': \"Annotation of the argument: `model_checkpoint` with default value: `'gpt-4o-2024-08-06'`, and current annotation: `str`.\"}, 'prompt': {'default': 'str', 'description': 'Annotation of the argument: `prompt` with current annotation: `str`.'}, 'title': 'Model Checkpoint', 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['client', 'base64_image', 'input_type', 'prompt', 'model_checkpoint', 'returns'], 'title': 'Function_Acall_Model', 'type': 'object'}, 'Function_Encode_Image_To_Base64': {'properties': {'image_path': {'image_path': {'default': 'str', 'description': 'Annotation of the argument: `image_path` with current annotation: `str`.'}, 'title': 'Image Path', 'type': 'string'}, 'returns': {'default': 'str', 'description': 'Return type annotation. This is the type hint that appears after the `->`. Current annotation: `str`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['image_path'], 'title': 'Function_Encode_Image_To_Base64', 'type': 'object'}, 'Function_Process_All_Pages': {'properties': {'client': {'base64_pages': {'description': 'Annotation of the argument: `base64_pages`.'}, 'client': {'description': 'Annotation of the argument: `client`.'}, 'input_type': {'description': 'Annotation of the argument: `input_type`.'}, 'model_checkpoint': {'description': 'Annotation of the argument: `model_checkpoint`.'}, 'prompt': {'description': 'Annotation of the argument: `prompt`.'}, 'title': 'Client', 'type': 'string'}, 'base64_pages': {'base64_pages': {'description': 'Annotation of the argument: `base64_pages`.'}, 'client': {'description': 'Annotation of the argument: `client`.'}, 'input_type': {'description': 'Annotation of the argument: `input_type`.'}, 'model_checkpoint': {'description': 'Annotation of the argument: `model_checkpoint`.'}, 'prompt': {'description': 'Annotation of the argument: `prompt`.'}, 'title': 'Base64 Pages', 'type': 'string'}, 'input_type': {'base64_pages': {'description': 'Annotation of the argument: `base64_pages`.'}, 'client': {'description': 'Annotation of the argument: `client`.'}, 'input_type': {'description': 'Annotation of the argument: `input_type`.'}, 'model_checkpoint': {'description': 'Annotation of the argument: `model_checkpoint`.'}, 'prompt': {'description': 'Annotation of the argument: `prompt`.'}, 'title': 'Input Type', 'type': 'string'}, 'prompt': {'base64_pages': {'description': 'Annotation of the argument: `base64_pages`.'}, 'client': {'description': 'Annotation of the argument: `client`.'}, 'input_type': {'description': 'Annotation of the argument: `input_type`.'}, 'model_checkpoint': {'description': 'Annotation of the argument: `model_checkpoint`.'}, 'prompt': {'description': 'Annotation of the argument: `prompt`.'}, 'title': 'Prompt', 'type': 'string'}, 'model_checkpoint': {'base64_pages': {'description': 'Annotation of the argument: `base64_pages`.'}, 'client': {'description': 'Annotation of the argument: `client`.'}, 'input_type': {'description': 'Annotation of the argument: `input_type`.'}, 'model_checkpoint': {'description': 'Annotation of the argument: `model_checkpoint`.'}, 'prompt': {'description': 'Annotation of the argument: `prompt`.'}, 'title': 'Model Checkpoint', 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['client', 'base64_pages', 'input_type', 'prompt', 'model_checkpoint', 'returns'], 'title': 'Function_Process_All_Pages', 'type': 'object'}, 'Function_Process_Page': {'properties': {'client': {'base64_page': {'description': 'Annotation of the argument: `base64_page`.'}, 'client': {'description': 'Annotation of the argument: `client`.'}, 'input_type': {'description': 'Annotation of the argument: `input_type`.'}, 'model_checkpoint': {'description': 'Annotation of the argument: `model_checkpoint`.'}, 'page_num': {'description': 'Annotation of the argument: `page_num`.'}, 'prompt': {'description': 'Annotation of the argument: `prompt`.'}, 'title': 'Client', 'type': 'string'}, 'base64_page': {'base64_page': {'description': 'Annotation of the argument: `base64_page`.'}, 'client': {'description': 'Annotation of the argument: `client`.'}, 'input_type': {'description': 'Annotation of the argument: `input_type`.'}, 'model_checkpoint': {'description': 'Annotation of the argument: `model_checkpoint`.'}, 'page_num': {'description': 'Annotation of the argument: `page_num`.'}, 'prompt': {'description': 'Annotation of the argument: `prompt`.'}, 'title': 'Base64 Page', 'type': 'string'}, 'input_type': {'base64_page': {'description': 'Annotation of the argument: `base64_page`.'}, 'client': {'description': 'Annotation of the argument: `client`.'}, 'input_type': {'description': 'Annotation of the argument: `input_type`.'}, 'model_checkpoint': {'description': 'Annotation of the argument: `model_checkpoint`.'}, 'page_num': {'description': 'Annotation of the argument: `page_num`.'}, 'prompt': {'description': 'Annotation of the argument: `prompt`.'}, 'title': 'Input Type', 'type': 'string'}, 'prompt': {'base64_page': {'description': 'Annotation of the argument: `base64_page`.'}, 'client': {'description': 'Annotation of the argument: `client`.'}, 'input_type': {'description': 'Annotation of the argument: `input_type`.'}, 'model_checkpoint': {'description': 'Annotation of the argument: `model_checkpoint`.'}, 'page_num': {'description': 'Annotation of the argument: `page_num`.'}, 'prompt': {'description': 'Annotation of the argument: `prompt`.'}, 'title': 'Prompt', 'type': 'string'}, 'model_checkpoint': {'base64_page': {'description': 'Annotation of the argument: `base64_page`.'}, 'client': {'description': 'Annotation of the argument: `client`.'}, 'input_type': {'description': 'Annotation of the argument: `input_type`.'}, 'model_checkpoint': {'description': 'Annotation of the argument: `model_checkpoint`.'}, 'page_num': {'description': 'Annotation of the argument: `page_num`.'}, 'prompt': {'description': 'Annotation of the argument: `prompt`.'}, 'title': 'Model Checkpoint', 'type': 'string'}, 'page_num': {'base64_page': {'description': 'Annotation of the argument: `base64_page`.'}, 'client': {'description': 'Annotation of the argument: `client`.'}, 'input_type': {'description': 'Annotation of the argument: `input_type`.'}, 'model_checkpoint': {'description': 'Annotation of the argument: `model_checkpoint`.'}, 'page_num': {'description': 'Annotation of the argument: `page_num`.'}, 'prompt': {'description': 'Annotation of the argument: `prompt`.'}, 'title': 'Page Num', 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['client', 'base64_page', 'input_type', 'prompt', 'model_checkpoint', 'page_num', 'returns'], 'title': 'Function_Process_Page', 'type': 'object'}}, 'properties': {'Function_Encode_Image_To_Base64': {'$ref': '#/$defs/Function_Encode_Image_To_Base64'}, 'Function_Acall_Model': {'$ref': '#/$defs/Function_Acall_Model'}, 'Function_Process_Page': {'$ref': '#/$defs/Function_Process_Page'}, 'Function_Process_All_Pages': {'$ref': '#/$defs/Function_Process_All_Pages'}}, 'required': ['Function_Encode_Image_To_Base64', 'Function_Acall_Model', 'Function_Process_Page', 'Function_Process_All_Pages'], 'title': 'ArgumentsModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '{"Function_Encode_Image_To_Base64": {"image_path": "str", "returns": "str"}, "Function_Acall_Model": {"client": "Client", "base64_image": "str", "input_type": "Literal[\'png\', \'jpg\', \'jpeg\', \'gif\', \'webp\']", "prompt": "str", "model_checkpoint": "str", "returns": "str"}, "Function_Process_Page": {"client": "Client", "base64_page": "str", "input_type": "Literal[\'png\', \'jpg\', \'jpeg\', \'gif\', \'webp\']", "prompt": "str", "model_checkpoint": "str", "page_num": "int", "returns": "tuple[str, int]"}, "Function_Process_All_Pages": {"client": "Client", "base64_pages": "list[str]", "input_type": "Literal[\'png\', \'jpg\', \'jpeg\', \'gif\', \'webp\']", "prompt": "str", "model_checkpoint": "str", "returns": "str"}}',
    },
    {
        "role": "user",
        "content": "Input code:\n```\nimport torch\nfrom typing import Union\nfrom diffusers.pipelines import FluxPipeline\nfrom PIL import Image\nimport numpy as np\nimport cv2\n\nfrom .common.base import BaseCondition\n\ncondition_dict = {\n    \"depth\": 0,\n    \"canny\": 1,\n    \"subject\": 4,\n    \"coloring\": 6,\n    \"deblurring\": 7,\n    \"fill\": 9,\n}\n\n\nclass Condition(BaseCondition):\n    def __init__(\n        self,\n        condition_type: str,\n        raw_img: Union[Image.Image, torch.Tensor] = None,\n        condition: Union[Image.Image, torch.Tensor] = None,\n        mask=None,\n        type_id: int = 0\n    ):\n        super().__init__()\n        self.condition_type = condition_type\n        assert raw_img is not None or condition is not None\n        if raw_img is not None:\n            self.condition = self.get_condition(condition_type, raw_img)\n        else:\n            self.condition = condition\n        self.type_id = type_id\n        # TODO: Add mask support\n        assert mask is None, \"Mask not supported yet\"\n\n    @staticmethod\n    def calculate_condition_score(image, weights = None):\n        \"\"\"\n        Calculates a weighted condition score based on image brightness, contrast, and edge density.\n        Args:\n            image: Input PIL Image\n            weights: Optional list of weights for [brightness, contrast, edges]. Defaults to [0.4, 0.3, 0.3]\n        Returns:\n            float: Weighted condition score between 0 and 1\n        \"\"\"\n        weights = weights or [0.4, 0.3, 0.3]\n        img_array = np.array(image.convert('L'))\n        brightness = np.mean(img_array) / 255\n        contrast = np.std(img_array) / 128\n        edges = cv2.Canny(img_array, 100, 200).sum() / (img_array.size * 255)\n        return np.clip(np.dot([brightness, contrast, edges], weights), 0, 1)\n\n    def validate_and_resize(self, target_size: tuple):\n        \"\"\"`target_size`: Desired dimensions (width, height) for the condition image.\"\"\"\n        if self.condition.size != target_size:\n            self.condition = self.condition.resize(target_size, Image.Resampling.LANCZOS)\n        if self.condition.mode != 'RGB':\n            self.condition = self.condition.convert('RGB')\n    @property\n    def type_id(self) -> int:\n        return condition_dict[self.condition_type]\n\n    @classmethod\n    def get_type_id(cls, condition_type: str):\n        \"\"\"Returns the type id of the condition.\"\"\"\n        return condition_dict[condition_type]\n\n    async def _encode_image(\n        self, pipe, cond_img\n    ):\n        # Convert synchronous operations to async using asyncio.to_thread if needed\n        cond_img = pipe.image_processor.preprocess(cond_img)\n        cond_img = cond_img.to(pipe.device).to(pipe.dtype)\n\n        # VAE encoding might be computationally intensive, but since it's using PyTorch,\n        # it's already optimized for GPU operations\n        cond_img = pipe.vae.encode(cond_img).latent_dist.sample()\n        cond_img = (\n                           cond_img - pipe.vae.config.shift_factor\n                   ) * pipe.vae.config.scaling_factor\n\n        cond_tokens = pipe._pack_latents(cond_img, *cond_img.shape)\n        cond_ids = pipe._prepare_latent_image_ids(\n            cond_img.shape[0],\n            cond_img.shape[2],\n            cond_img.shape[3],\n            pipe.device,\n            pipe.dtype,\n        )\n\n        return cond_tokens, cond_ids\n\n    async def encode(self, pipe):\n        if self.condition_type in [\n            \"depth\",\n            \"canny\",\n            \"subject\",\n            \"coloring\",\n            \"deblurring\",\n            \"fill\",\n        ]:\n            tokens, ids = await self._encode_image(pipe, self.condition)\n        else:\n            raise NotImplementedError(\n                f\"Condition type {self.condition_type} not implemented\"\n            )\n\n        type_id = ids[:, 0].item() * self.type_id\n        return tokens, ids, type_id\n```\n\nJson schema:\n```\n{'$defs': {'ClassConditionMethodCalculate_Condition_Score': {'properties': {'image': {'image': {'description': 'Annotation of the argument: `image`.'}, 'title': 'Image', 'type': 'string', 'weights': {'description': 'Annotation of the argument: `weights` with default value: `None`.'}}, 'weights': {'image': {'description': 'Annotation of the argument: `image`.'}, 'title': 'Weights', 'type': 'string', 'weights': {'description': 'Annotation of the argument: `weights` with default value: `None`.'}}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['image', 'weights', 'returns'], 'title': 'ClassConditionMethodCalculate_Condition_Score', 'type': 'object'}, 'ClassConditionMethodEncode': {'properties': {'pipe': {'pipe': {'description': 'Annotation of the argument: `pipe`.'}, 'title': 'Pipe', 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['pipe', 'returns'], 'title': 'ClassConditionMethodEncode', 'type': 'object'}, 'ClassConditionMethodGet_Type_Id': {'properties': {'condition_type': {'condition_type': {'default': 'str', 'description': 'Annotation of the argument: `condition_type` with current annotation: `str`.'}, 'title': 'Condition Type', 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['condition_type', 'returns'], 'title': 'ClassConditionMethodGet_Type_Id', 'type': 'object'}, 'ClassConditionMethodType_Id': {'properties': {'returns': {'default': 'int', 'description': 'Return type annotation. This is the type hint that appears after the `->`. Current annotation: `int`.', 'title': 'Returns', 'type': 'string'}}, 'title': 'ClassConditionMethodType_Id', 'type': 'object'}, 'ClassConditionMethodValidate_And_Resize': {'properties': {'target_size': {'target_size': {'default': 'tuple', 'description': 'Annotation of the argument: `target_size` with current annotation: `tuple`.'}, 'title': 'Target Size', 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['target_size', 'returns'], 'title': 'ClassConditionMethodValidate_And_Resize', 'type': 'object'}, 'ClassConditionMethod_Encode_Image': {'properties': {'pipe': {'cond_img': {'description': 'Annotation of the argument: `cond_img`.'}, 'pipe': {'description': 'Annotation of the argument: `pipe`.'}, 'title': 'Pipe', 'type': 'string'}, 'cond_img': {'cond_img': {'description': 'Annotation of the argument: `cond_img`.'}, 'pipe': {'description': 'Annotation of the argument: `pipe`.'}, 'title': 'Cond Img', 'type': 'string'}, 'returns': {'description': 'Return type annotation. This is the type hint that appears after the `->`.', 'title': 'Returns', 'type': 'string'}}, 'required': ['pipe', 'cond_img', 'returns'], 'title': 'ClassConditionMethod_Encode_Image', 'type': 'object'}, 'ClassConditionMethod__Init__': {'properties': {'condition_type': {'condition': {'default': 'Union[Image.Image, torch.Tensor]', 'description': 'Annotation of the argument: `condition` with default value: `None`, and current annotation: `Union[Image.Image, torch.Tensor]`.'}, 'condition_type': {'default': 'str', 'description': 'Annotation of the argument: `condition_type` with current annotation: `str`.'}, 'mask': {'description': 'Annotation of the argument: `mask` with default value: `None`.'}, 'raw_img': {'default': 'Union[Image.Image, torch.Tensor]', 'description': 'Annotation of the argument: `raw_img` with default value: `None`, and current annotation: `Union[Image.Image, torch.Tensor]`.'}, 'title': 'Condition Type', 'type': 'string', 'type_id': {'default': 'int', 'description': 'Annotation of the argument: `type_id` with default value: `0`, and current annotation: `int`.'}}, 'raw_img': {'condition': {'default': 'Union[Image.Image, torch.Tensor]', 'description': 'Annotation of the argument: `condition` with default value: `None`, and current annotation: `Union[Image.Image, torch.Tensor]`.'}, 'condition_type': {'default': 'str', 'description': 'Annotation of the argument: `condition_type` with current annotation: `str`.'}, 'mask': {'description': 'Annotation of the argument: `mask` with default value: `None`.'}, 'raw_img': {'default': 'Union[Image.Image, torch.Tensor]', 'description': 'Annotation of the argument: `raw_img` with default value: `None`, and current annotation: `Union[Image.Image, torch.Tensor]`.'}, 'title': 'Raw Img', 'type': 'string', 'type_id': {'default': 'int', 'description': 'Annotation of the argument: `type_id` with default value: `0`, and current annotation: `int`.'}}, 'condition': {'condition': {'default': 'Union[Image.Image, torch.Tensor]', 'description': 'Annotation of the argument: `condition` with default value: `None`, and current annotation: `Union[Image.Image, torch.Tensor]`.'}, 'condition_type': {'default': 'str', 'description': 'Annotation of the argument: `condition_type` with current annotation: `str`.'}, 'mask': {'description': 'Annotation of the argument: `mask` with default value: `None`.'}, 'raw_img': {'default': 'Union[Image.Image, torch.Tensor]', 'description': 'Annotation of the argument: `raw_img` with default value: `None`, and current annotation: `Union[Image.Image, torch.Tensor]`.'}, 'title': 'Condition', 'type': 'string', 'type_id': {'default': 'int', 'description': 'Annotation of the argument: `type_id` with default value: `0`, and current annotation: `int`.'}}, 'mask': {'condition': {'default': 'Union[Image.Image, torch.Tensor]', 'description': 'Annotation of the argument: `condition` with default value: `None`, and current annotation: `Union[Image.Image, torch.Tensor]`.'}, 'condition_type': {'default': 'str', 'description': 'Annotation of the argument: `condition_type` with current annotation: `str`.'}, 'mask': {'description': 'Annotation of the argument: `mask` with default value: `None`.'}, 'raw_img': {'default': 'Union[Image.Image, torch.Tensor]', 'description': 'Annotation of the argument: `raw_img` with default value: `None`, and current annotation: `Union[Image.Image, torch.Tensor]`.'}, 'title': 'Mask', 'type': 'string', 'type_id': {'default': 'int', 'description': 'Annotation of the argument: `type_id` with default value: `0`, and current annotation: `int`.'}}, 'type_id': {'condition': {'default': 'Union[Image.Image, torch.Tensor]', 'description': 'Annotation of the argument: `condition` with default value: `None`, and current annotation: `Union[Image.Image, torch.Tensor]`.'}, 'condition_type': {'default': 'str', 'description': 'Annotation of the argument: `condition_type` with current annotation: `str`.'}, 'mask': {'description': 'Annotation of the argument: `mask` with default value: `None`.'}, 'raw_img': {'default': 'Union[Image.Image, torch.Tensor]', 'description': 'Annotation of the argument: `raw_img` with default value: `None`, and current annotation: `Union[Image.Image, torch.Tensor]`.'}, 'title': 'Type Id', 'type': 'string', 'type_id': {'default': 'int', 'description': 'Annotation of the argument: `type_id` with default value: `0`, and current annotation: `int`.'}}}, 'required': ['condition_type', 'raw_img', 'condition', 'mask', 'type_id'], 'title': 'ClassConditionMethod__Init__', 'type': 'object'}}, 'properties': {'ClassConditionMethod__Init__': {'$ref': '#/$defs/ClassConditionMethod__Init__'}, 'ClassConditionMethodCalculate_Condition_Score': {'$ref': '#/$defs/ClassConditionMethodCalculate_Condition_Score'}, 'ClassConditionMethodValidate_And_Resize': {'$ref': '#/$defs/ClassConditionMethodValidate_And_Resize'}, 'ClassConditionMethodType_Id': {'$ref': '#/$defs/ClassConditionMethodType_Id'}, 'ClassConditionMethodGet_Type_Id': {'$ref': '#/$defs/ClassConditionMethodGet_Type_Id'}, 'ClassConditionMethod_Encode_Image': {'$ref': '#/$defs/ClassConditionMethod_Encode_Image'}, 'ClassConditionMethodEncode': {'$ref': '#/$defs/ClassConditionMethodEncode'}}, 'required': ['ClassConditionMethod__Init__', 'ClassConditionMethodCalculate_Condition_Score', 'ClassConditionMethodValidate_And_Resize', 'ClassConditionMethodType_Id', 'ClassConditionMethodGet_Type_Id', 'ClassConditionMethod_Encode_Image', 'ClassConditionMethodEncode'], 'title': 'ArgumentsModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '{"ClassConditionMethod__Init__": {"condition_type": "str", "raw_img": "Optional[Union[Image.Image, torch.Tensor]]", "condition": "Optional[Union[Image.Image, torch.Tensor]]", "mask": "Optional[Any]", "type_id": "int"}, "ClassConditionMethodCalculate_Condition_Score": {"image": "Image.Image", "weights": "Optional[list[float]]", "returns": "float"}, "ClassConditionMethodValidate_And_Resize": {"target_size": "tuple[int, int]", "returns": "None"}, "ClassConditionMethodType_Id": {"returns": "int"}, "ClassConditionMethodGet_Type_Id": {"condition_type": "str", "returns": "int"}, "ClassConditionMethod_Encode_Image": {"pipe": "FluxPipeline", "cond_img": "Union[Image.Image, torch.Tensor]", "returns": "tuple[torch.Tensor, torch.Tensor]"}, "ClassConditionMethodEncode": {"pipe": "FluxPipeline", "returns": "tuple[torch.Tensor, torch.Tensor, int]"}}',
    },
]

MESSAGES_DOCSTRING = [
    {
        "role": "system",
        "content": 'Act as an experienced Python specialist.\n\nWrite a docstring in the Google style for each function, class, and class method from the input code, following the provided json schema, if and only if you are confident that the docstring is correct and required for better understanding of the code. If you are not sure how the docstring should look like, leave it empty. If the function/class/method is very simple to understand without documentation or is dummy, leave it empty as well.\n\nFor functions and methods that need docstrings, use this template:\n```\n<General description of the purpose of the function / method>\n\nArgs:\n    arg_1 (`<type of the arg_1>`, <default value if exists>):\n    <description of the arg_1>\n    ...\n    arg_n (`<type of the arg_n>`, <default value if exists>):\n    <description of the arg_n>\n\nReturns:\n    `<type of the returns>`: <description of the returns>\n\nRaises:\n    `<ExceptionType>`: <description of when this exception is raised> (include only if applicable)\n```\n\nAlways include the `Args` and `Returns` sections for methods and functions.\n\nFor classes, use the template below:\n```\n<General description of the purpose of the class>\n\nArgs:\n    arg_1 (`<type of the arg_1>`, <default value if exists>):\n    <description of the arg_1>\n    ...\n    arg_n (`<type of the arg_n>`, <default value if exists>):\n    <description of the arg_n>\n\nMethods:\n    method_1(arg_1: `<type of the arg_1>`, ..., arg_n: `<type of the arg_n>`): <one-sentnce description of what method_1 does>\n    ...\n```',
    },
    {
        "role": "user",
        "content": "Input code:\n```\nimport warnings\nimport weakref\nfrom collections import Counter\nfrom random import sample\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    List,\n    Optional,\n    Union,\n)\n\nimport numpy as np\nimport pyarrow as pa\nimport pyarrow.compute as pc\n\nfrom . import config\nfrom .features.features import (\n    _align_features,\n    _check_if_features_can_be_aligned,\n)\nfrom .fingerprint import (\n    update_fingerprint,\n)\nfrom .info import DatasetInfo\nfrom .splits import NamedSplit\nfrom .table import (\n    InMemoryTable,\n    concat_tables,\n)\nfrom .utils import logging\nfrom .utils.py_utils import (\n    Literal,\n)\nfrom .dataset import Dataset\nfrom .utils.tf_utils import dataset_to_tf, minimal_tf_collate_fn, multiprocess_dataset_to_tf\n\nlogger = logging.get_logger(__name__)\n\nPUSH_TO_HUB_WITHOUT_METADATA_CONFIGS_SPLIT_PATTERN_SHARDED = (\n    \"data/{split}-[0-9][0-9][0-9][0-9][0-9]-of-[0-9][0-9][0-9][0-9][0-9]*.parquet\"\n)\n\n\nclass TensorflowDatasetMixin:\n    name: str = ''\n    cache_dir: Optional[str] = None\n    _TF_DATASET_REFS = set()\n\n    @staticmethod\n    def _get_output_signature(\n        dataset: \"Dataset\",\n        collate_fn: Callable,\n        collate_fn_args: dict,\n        cols_to_retain: Optional[List[str]] = None,\n        batch_size: Optional[int] = None,\n        num_test_batches: int = 20,\n    ):\n        if config.TF_AVAILABLE:\n            import tensorflow as tf\n        else:\n            raise ImportError(\"Called a Tensorflow-specific function but Tensorflow is not installed.\")\n\n        if len(dataset) == 0:\n            raise ValueError(\"Unable to get the output signature because the dataset is empty.\")\n        if batch_size is not None:\n            batch_size = min(len(dataset), batch_size)\n        test_batch_size = 1\n\n        if cols_to_retain is not None:\n            cols_to_retain = list(set(cols_to_retain + [\"label_ids\", \"label\", \"labels\"]))\n\n        test_batches = []\n        for _ in range(num_test_batches):\n            indices = sample(range(len(dataset)), test_batch_size)\n            test_batch = dataset[indices]\n            if cols_to_retain is not None:\n                test_batch = {key: value for key, value in test_batch.items() if key in cols_to_retain}\n            test_batch = [{key: value[i] for key, value in test_batch.items()} for i in range(test_batch_size)]\n            test_batch = collate_fn(test_batch, **collate_fn_args)\n            test_batches.append(test_batch)\n\n        tf_columns_to_signatures = {}\n        np_columns_to_dtypes = {}\n        for column in test_batches[0].keys():\n            raw_arrays = [batch[column] for batch in test_batches]\n            # In case the collate_fn returns something strange\n            np_arrays = []\n            for array in raw_arrays:\n                if isinstance(array, np.ndarray):\n                    np_arrays.append(array)\n                elif isinstance(array, tf.Tensor):\n                    np_arrays.append(array.numpy())\n                else:\n                    np_arrays.append(np.array(array))\n\n            if np.issubdtype(np_arrays[0].dtype, np.integer) or np_arrays[0].dtype == bool:\n                tf_dtype = tf.int64\n                np_dtype = np.int64\n            elif np.issubdtype(np_arrays[0].dtype, np.number):\n                tf_dtype = tf.float32\n                np_dtype = np.float32\n            elif np_arrays[0].dtype.kind == \"U\":  # Unicode strings\n                np_dtype = np.str_\n                tf_dtype = tf.string\n            else:\n                raise RuntimeError(\n                    f\"Unrecognized array dtype {np_arrays[0].dtype}. \\n\"\n                    \"Nested types and image/audio types are not supported yet.\"\n                )\n            shapes = [array.shape for array in np_arrays]\n            static_shape = []\n            for dim in range(len(shapes[0])):\n                sizes = {shape[dim] for shape in shapes}\n                if dim == 0:\n                    static_shape.append(batch_size)\n                    continue\n                if len(sizes) == 1:  # This dimension looks constant\n                    static_shape.append(sizes.pop())\n                else:  # Use None for variable dimensions\n                    static_shape.append(None)\n            tf_columns_to_signatures[column] = tf.TensorSpec(shape=static_shape, dtype=tf_dtype)\n            np_columns_to_dtypes[column] = np_dtype\n\n        return tf_columns_to_signatures, np_columns_to_dtypes\n\n    def to_tf_dataset(\n        self,\n        batch_size: Optional[int] = None,\n        columns: Optional[Union[str, List[str]]] = None,\n        shuffle: bool = False,\n        collate_fn: Optional[Callable] = None,\n        drop_remainder: bool = False,\n        collate_fn_args: Optional[Dict[str, Any]] = None,\n        label_cols: Optional[Union[str, List[str]]] = None,\n        prefetch: bool = True,\n        num_workers: int = 0,\n        num_test_batches: int = 20,\n    ):\n        if config.TF_AVAILABLE:\n            import tensorflow as tf\n        else:\n            raise ImportError(\"Called a Tensorflow-specific function but Tensorflow is not installed.\")\n\n        if (isinstance(columns, list) and len(columns) == 1) or (\n            isinstance(label_cols, list) and len(label_cols) == 1\n        ):\n            warnings.warn(\n                \"The output of `to_tf_dataset` will change when a passing single element list for `labels` or \"\n                \"`columns` in the next datasets version. To return a tuple structure rather than dict, pass a \"\n                \"single string.\\n\"\n                \"Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \\n\"\n                \"             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \\n\"\n                \"New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \\n\"\n                \"             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \",\n                FutureWarning,\n            )\n\n        if isinstance(tf.distribute.get_strategy(), tf.distribute.TPUStrategy):\n            logger.warning(\n                \"Note that to_tf_dataset() loads the data with a generator rather than a full tf.data \"\n                \"pipeline and is not compatible with remote TPU connections. If you encounter errors, please \"\n                \"try using a TPU VM or, if your data can fit in memory, loading it into memory as a dict of \"\n                \"Tensors instead of streaming with to_tf_dataset().\"\n            )\n\n        if collate_fn is None:\n            # Set a very simple default collator that just stacks things together\n            collate_fn = minimal_tf_collate_fn\n        if collate_fn_args is None:\n            collate_fn_args = {}\n        if label_cols and not columns:\n            raise ValueError(\"Cannot specify label_cols without specifying columns!\")\n        if label_cols is None:\n            label_cols = []\n        elif isinstance(label_cols, str):\n            label_cols = [label_cols]\n        if len(set(label_cols)) < len(label_cols):\n            raise ValueError(\"List of label_cols contains duplicates.\")\n        if columns:\n            if isinstance(columns, str):\n                columns = [columns]\n            if len(set(columns)) < len(columns):\n                raise ValueError(\"List of columns contains duplicates.\")\n            cols_to_retain = list(set(columns + label_cols))\n        else:\n            cols_to_retain = None  # Indicates keeping all valid columns\n            columns = []\n\n        if self.format[\"type\"] not in [\"custom\", \"numpy\"]:\n            dataset = self.with_format(\"numpy\")\n        else:\n            dataset = self\n\n        # TODO(Matt, QL): deprecate the retention of label_ids and label\n\n        output_signature, columns_to_np_types = dataset._get_output_signature(\n            dataset,\n            collate_fn=collate_fn,\n            collate_fn_args=collate_fn_args,\n            cols_to_retain=cols_to_retain,\n            batch_size=batch_size if drop_remainder else None,\n            num_test_batches=num_test_batches,\n        )\n\n        if \"labels\" in output_signature:\n            if (\"label_ids\" in columns or \"label\" in columns) and \"labels\" not in columns:\n                columns = [col for col in columns if col not in [\"label_ids\", \"label\"]] + [\"labels\"]\n            if (\"label_ids\" in label_cols or \"label\" in label_cols) and \"labels\" not in label_cols:\n                label_cols = [col for col in label_cols if col not in [\"label_ids\", \"label\"]] + [\"labels\"]\n\n        for col in columns:\n            if col not in output_signature:\n                raise ValueError(f\"Column {col} not found in dataset!\")\n\n        for col in label_cols:\n            if col not in output_signature:\n                raise ValueError(f\"Label column {col} not found in dataset!\")\n\n        if num_workers == 0:\n            tf_dataset = dataset_to_tf(\n                dataset=dataset,\n                cols_to_retain=cols_to_retain,\n                collate_fn=collate_fn,\n                collate_fn_args=collate_fn_args,\n                columns_to_np_types=columns_to_np_types,\n                output_signature=output_signature,\n                shuffle=shuffle,\n                batch_size=batch_size,\n                drop_remainder=drop_remainder,\n            )\n        elif num_workers > 0:\n            if batch_size is None:\n                raise NotImplementedError(\n                    \"`batch_size` must be specified when using multiple workers, as unbatched multiprocessing \"\n                    \"is not supported yet. Please provide a `batch_size` if `num_workers` is greater than 0.\"\n                )\n            tf_dataset = multiprocess_dataset_to_tf(\n                dataset=dataset,\n                cols_to_retain=cols_to_retain,\n                collate_fn=collate_fn,\n                collate_fn_args=collate_fn_args,\n                columns_to_np_types=columns_to_np_types,\n                output_signature=output_signature,\n                shuffle=shuffle,\n                batch_size=batch_size,\n                drop_remainder=drop_remainder,\n                num_workers=num_workers,\n            )\n        else:\n            raise ValueError(\"num_workers must be >= 0\")\n\n        def split_features_and_labels(input_batch):\n            # TODO(Matt, QL): deprecate returning the dict content when there's only one key\n            features = {key: tensor for key, tensor in input_batch.items() if key in columns}\n            labels = {key: tensor for key, tensor in input_batch.items() if key in label_cols}\n            if len(features) == 1:\n                features = list(features.values())[0]\n            if len(labels) == 1:\n                labels = list(labels.values())[0]\n            if isinstance(labels, dict) and len(labels) == 0:\n                return features\n            else:\n                return features, labels\n\n        if cols_to_retain is not None:\n            tf_dataset = tf_dataset.map(split_features_and_labels)\n\n        if prefetch:\n            tf_dataset = tf_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n\n        # Remove a reference to the open Arrow file on delete\n        def cleanup_callback(ref):\n            dataset.__del__()\n            self._TF_DATASET_REFS.remove(ref)\n\n        self._TF_DATASET_REFS.add(weakref.ref(tf_dataset, cleanup_callback))\n\n        return tf_dataset\n\n    def save_to_cache(self) -> str:\n        if not self.name:\n            raise ValueError(\"Dataset name must be set to save\")\n            \n        save_path = os.path.join(self.cache_dir, self.name) if self.cache_dir else self.name\n        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n        \n        if config.TF_AVAILABLE:\n            import tensorflow as tf\n            tf.data.Dataset.save(self, save_path)\n        else:\n            np.save(save_path, self.with_format(\"numpy\"))\n            \n        return save_path\n\n\nclass DatasetTransformationNotAllowedError(Exception):\n    pass\n\n\ndef _check_column_names(column_names: List[str]):\n    \"\"\"Check the column names to make sure they don't contain duplicates.\"\"\"\n    counter = Counter(column_names)\n    if not all(count == 1 for count in counter.values()):\n        duplicated_columns = [col for col in counter if counter[col] > 1]\n        raise ValueError(f\"The table can't have duplicated columns but columns {duplicated_columns} are duplicated.\")\n\ndef _concatenate_map_style_datasets(\n    dsets: List[Dataset],\n    info: Optional[DatasetInfo] = None,\n    split: Optional[NamedSplit] = None,\n    axis: int = 0,\n):\n    # Ignore datasets with no rows\n    if any(dset.num_rows > 0 for dset in dsets):\n        dsets = [dset for dset in dsets if dset.num_rows > 0]\n    else:\n        # Return first dataset if all datasets are empty\n        return dsets[0]\n\n    # Perform checks (and a potentional cast if axis=0)\n    if axis == 0:\n        _check_if_features_can_be_aligned([dset.features for dset in dsets])\n    else:\n        if not all(dset.num_rows == dsets[0].num_rows for dset in dsets):\n            raise ValueError(\"Number of rows must match for all datasets\")\n        _check_column_names([col_name for dset in dsets for col_name in dset._data.column_names])\n\n    # Find common format or reset format\n    format = dsets[0].format\n    if any(dset.format != format for dset in dsets):\n        format = {}\n        logger.info(\"Some of the datasets have disparate format. Resetting the format of the concatenated dataset.\")\n\n    def apply_offset_to_indices_table(table, offset):\n        if offset == 0:\n            return table\n        else:\n            array = table[\"indices\"]\n            new_array = pc.add(array, pa.scalar(offset, type=pa.uint64()))\n            return InMemoryTable.from_arrays([new_array], names=[\"indices\"])\n\n    # Concatenate indices if they exist\n    if any(dset._indices is not None for dset in dsets):\n        if axis == 0:\n            # Datasets with no indices tables are replaced with a dataset with an indices table in memory.\n            # Applying an offset to an indices table also brings the table in memory.\n            indices_tables = []\n            for i in range(len(dsets)):\n                if dsets[i]._indices is None:\n                    dsets[i] = dsets[i]._select_with_indices_mapping(range(len(dsets[i])))\n                indices_tables.append(dsets[i]._indices)\n\n            # An offset needs to be applied to the indices before concatenating\n            offset = 0\n            for i in range(len(dsets)):\n                indices_tables[i] = apply_offset_to_indices_table(indices_tables[i], offset)\n                offset += len(dsets[i]._data)\n\n            # Concatenate indices\n            indices_tables = [t for t in indices_tables if len(t) > 0]\n            if indices_tables:\n                indices_table = concat_tables(indices_tables)\n            else:\n                indices_table = InMemoryTable.from_batches([], schema=pa.schema({\"indices\": pa.int64()}))\n        else:\n            if len(dsets) == 1:\n                indices_table = dsets[0]._indices\n            else:\n                for i in range(len(dsets)):\n                    dsets[i] = dsets[i].flatten_indices()\n                indices_table = None\n    else:\n        indices_table = None\n\n    table = concat_tables([dset._data for dset in dsets], axis=axis)\n    if axis == 0:\n        features_list = _align_features([dset.features for dset in dsets])\n    else:\n        features_list = [dset.features for dset in dsets]\n    table = update_metadata_with_features(table, {k: v for features in features_list for k, v in features.items()})\n\n    # Concatenate infos\n    if info is None:\n        info = DatasetInfo.from_merge([dset.info for dset in dsets])\n    fingerprint = update_fingerprint(\n        \"\".join(dset._fingerprint for dset in dsets), _concatenate_map_style_datasets, {\"info\": info, \"split\": split}\n    )\n\n    # Make final concatenated dataset\n    concatenated_dataset = Dataset(\n        table,\n        info=info,\n        split=split,\n        indices_table=indices_table,\n        fingerprint=fingerprint,\n    )\n    concatenated_dataset.set_format(**format)\n    return concatenated_dataset\n\n\ndef _interleave_map_style_datasets(\n    datasets: List[\"Dataset\"],\n    probabilities: Optional[List[float]] = None,\n    seed: Optional[int] = None,\n    info: Optional[DatasetInfo] = None,\n    split: Optional[NamedSplit] = None,\n    stopping_strategy: Literal[\"first_exhausted\", \"all_exhausted\"] = \"first_exhausted\",\n    **kwargs,\n) -> \"Dataset\":\n    if stopping_strategy not in [\"first_exhausted\", \"all_exhausted\"]:\n        raise ValueError(\n            f\"{stopping_strategy} stopping strategy in `interleave_datasets` is not implemented yet with a list of {type(datasets[0])}\"\n        )\n\n    # To interleave the datasets, we concatenate them and then we re-order the indices\n    concatenated_datasets = _concatenate_map_style_datasets(datasets, info=info, split=split)\n\n    # Let's now build the indices to pass to .select()\n    lengths = [len(dset) for dset in datasets]\n    offsets = np.cumsum([0] + lengths[:-1])\n\n    # if stopping_strategy is \"first_exhausted\", it is an undersampling situation whereas it is an oversampling situation if it is \"all_exhausted\"\n    oversampling = stopping_strategy == \"all_exhausted\"\n\n    if probabilities is None and not oversampling:\n        # Undersampling situation with cycling between each sources\n        # Example:: If lengths of the datasets are [3, 4, 5]\n        # Then the resulting indices should be [0, 3, 7, 1, 4, 8, 2, 6, 9]\n        # Note that we only have 3 examples per dataset since the first dataset ran out of examples\n\n        # Reasoning behind the following operation: keeping the min_length first indices of each dataset\n        # while offsetting in order to correspond to the right indices of the concatenated dataset\n        # and flattening to effectively interleave the datasets\n        indices = (offsets.reshape(1, -1) + np.arange(min(lengths)).reshape(-1, 1)).flatten().tolist()\n    elif probabilities is None:\n        # Oversampling situation with cycling between each sources\n        # Then the resulting indices should be [0, 3, 7, 1, 4, 8, 2, 5, 9, 0, 6, 10, 1, 3, 11]\n        # Note that we have 5 examples per dataset with a rolling window since the longest dataset has 5 samples\n\n        # Reasoning behind the following operation: for each dataset indices (i.e column) repeat the indices to have max_length indices per dataset\n        # For example, if the max_length is 5 and the i-th dataset has 3 samples, the i-th column will be [0,1,2,0,1]\n        indices = np.mod(np.arange(max(lengths)).reshape(-1, 1), np.array(lengths).reshape(1, -1))\n\n        # We have to keep the indices to their respective dataset offsets and to flatten to effectively interleave the datasets\n        indices = (indices + offsets).flatten().tolist()\n\n    else:\n        # boolean array indicating if at index i if the dataset_i has been fully exhausted\n        is_exhausted = np.full(len(lengths), False)\n\n        # if undersampling (\"first_exhausted\"), we stop as soon as one dataset is exhausted\n        # if oversampling (\"all_exhausted\"), we stop as soons as every dataset is exhausted, i.e as soon as every samples of every dataset has been visited at least once\n        bool_strategy_func = np.all if oversampling else np.any\n\n        def iter_random_indices():\n            \"\"\"Get an infinite iterator that randomly samples the index of the source to pick examples from.\"\"\"\n            rng = np.random.default_rng(seed)\n            while True:\n                yield from (int(i) for i in rng.choice(len(datasets), size=1000, p=probabilities))\n\n        current_index = [0] * len(datasets)\n        indices = []\n        for source_idx in iter_random_indices():\n            # If no oversampling, we stop as soon as a dataset has ran out of examples (np.any)\n            # Otherwise, we stop as soon as every dataset has ran out of examples (np.all)\n            if bool_strategy_func(is_exhausted):\n                # the stopping condition was reached, let's stop\n                break\n\n            # let's add the example at the current index of the `source_idx`-th dataset\n            indices.append(current_index[source_idx] + offsets[source_idx])\n            current_index[source_idx] += 1\n\n            # we've ran out of examples for the current dataset, let's update our boolean array and bring the current_index back to 0\n            if current_index[source_idx] >= lengths[source_idx]:\n                is_exhausted[source_idx] = True\n                current_index[source_idx] = 0\n\n    return concatenated_datasets.select(indices, **kwargs)\n\n\ndef _split_by_node_map_style_dataset(dataset: Dataset, rank: int, world_size: int) -> Dataset:\n    return dataset.shard(num_shards=world_size, index=rank, contiguous=True)\n```\n\nJson schema:\n```\n{'properties': {'class_TensorflowDatasetMixin': {'description': 'Docstring for the class `TensorflowDatasetMixin`', 'title': 'Class Tensorflowdatasetmixin', 'type': 'string'}, 'class_TensorflowDatasetMixin_method__get_output_signature': {'description': 'Docstring for the method `_get_output_signature` of the class `TensorflowDatasetMixin`', 'title': 'Class Tensorflowdatasetmixin Method  Get Output Signature', 'type': 'string'}, 'class_TensorflowDatasetMixin_method_to_tf_dataset': {'description': 'Docstring for the method `to_tf_dataset` of the class `TensorflowDatasetMixin`', 'title': 'Class Tensorflowdatasetmixin Method To Tf Dataset', 'type': 'string'}, 'class_TensorflowDatasetMixin_method_save_to_cache': {'description': 'Docstring for the method `save_to_cache` of the class `TensorflowDatasetMixin`', 'title': 'Class Tensorflowdatasetmixin Method Save To Cache', 'type': 'string'}, 'class_DatasetTransformationNotAllowedError': {'description': 'Docstring for the class `DatasetTransformationNotAllowedError`', 'title': 'Class Datasettransformationnotallowederror', 'type': 'string'}, 'function__check_column_names': {'description': 'Docstring for the function `_check_column_names`', 'title': 'Function  Check Column Names', 'type': 'string'}, 'function__concatenate_map_style_datasets': {'description': 'Docstring for the function `_concatenate_map_style_datasets`', 'title': 'Function  Concatenate Map Style Datasets', 'type': 'string'}, 'function__interleave_map_style_datasets': {'description': 'Docstring for the function `_interleave_map_style_datasets`', 'title': 'Function  Interleave Map Style Datasets', 'type': 'string'}, 'function__split_by_node_map_style_dataset': {'description': 'Docstring for the function `_split_by_node_map_style_dataset`', 'title': 'Function  Split By Node Map Style Dataset', 'type': 'string'}}, 'required': ['class_TensorflowDatasetMixin', 'class_TensorflowDatasetMixin_method__get_output_signature', 'class_TensorflowDatasetMixin_method_to_tf_dataset', 'class_TensorflowDatasetMixin_method_save_to_cache', 'class_DatasetTransformationNotAllowedError', 'function__check_column_names', 'function__concatenate_map_style_datasets', 'function__interleave_map_style_datasets', 'function__split_by_node_map_style_dataset'], 'title': 'DocstringModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '"""\n{"class_TensorflowDatasetMixin": "A mixin class that provides functionality to convert a `Dataset` object to a TensorFlow dataset.\\\\n\\\\nArgs:\\\\n\\\\tname (`str`):\\\\n\\\\t\\\\tName identifier for the dataset. Used for cache file naming.\\\\n\\\\tcache_dir (`str`, *optional*):\\\\n\\\\t\\\\tDirectory to cache the dataset. If None, uses current directory.\\\\n\\\\t_TF_DATASET_REFS (`set`):\\\\n\\\\t\\\\tSet to store weak references to TensorFlow datasets. Used for cleanup of Arrow file references.\\\\n\\\\nMethods:\\\\n\\\\t`save_to_cache()`: Saves dataset to disk using `cache_dir`/`name` or `name` as path.\\\\n\\\\t`to_tf_dataset()`: Converts dataset to TensorFlow format with batching and preprocessing options.\\\\n\\\\nPrivate Methods:\\\\n\\\\t`_get_output_signature()`: Determines TensorFlow output signatures for dataset elements.", "class_TensorflowDatasetMixin_method__get_output_signature": "Private method used by `to_tf_dataset()` to find the shapes and dtypes of samples from this dataset\\\\n   after being passed through the collate_fn. Tensorflow needs an exact signature for tf.numpy_function, so\\\\n   the only way to do this is to run test batches - the collator may add or rename columns, so we can\'t figure\\\\n   it out just by inspecting the dataset.\\\\n\\\\nArgs:\\\\n\\\\tdataset (`Dataset`):\\\\n\\\\t\\\\tDataset to load samples from.\\\\n\\\\tcollate_fn(`bool`):\\\\n\\\\t\\\\tShuffle the dataset order when loading. Recommended True for training, False for validation/evaluation.\\\\n\\\\tcollate_fn(`Callable`):\\\\n\\\\t\\\\tA function or callable object (such as a `DataCollator`) that will collate\\\\n\\\\t\\\\tlists of samples into a batch.\\\\n\\\\tcollate_fn_args (`Dict`):\\\\n\\\\t\\\\tA `dict` of keyword arguments to be passed to the\\\\n\\\\t\\\\t`collate_fn`.\\\\n\\\\tbatch_size (`int`, optional):\\\\n\\\\t\\\\tThe size of batches loaded from the dataset. Used for shape inference.\\\\n\\\\t\\\\tCan be None, which indicates that batch sizes can be variable.\\\\n\\\\tnum_test_batches (`int`):\\\\n\\\\t\\\\tThe number of batches to load from the dataset for shape inference.\\\\n\\\\nReturns:\\\\n\\\\t`dict`: Dict mapping column names to tf.Tensorspec objects\\\\n\\\\t`dict`: Dict mapping column names to np.dtype objects", "class_TensorflowDatasetMixin_method_to_tf_dataset": "Create a `tf.data.Dataset` from the underlying Dataset. This `tf.data.Dataset` will load and collate batches from\\\\nthe Dataset, and is suitable for passing to methods like `model.fit()` or `model.predict()`. The dataset will yield\\\\n`dicts` for both inputs and labels unless the `dict` would contain only a single key, in which case a raw\\\\n`tf.Tensor` is yielded instead.\\\\n\\\\nArgs:\\\\n\\\\tbatch_size (`int`, *optional*):\\\\n\\\\t\\\\tSize of batches to load from the dataset. Defaults to `None`, which implies that the dataset won\'t be\\\\n\\\\t\\\\tbatched, but the returned dataset can be batched later with `tf_dataset.batch(batch_size)`.\\\\n\\\\tcolumns (`List[str]` or `str`, *optional*):\\\\n\\\\t\\\\tDataset column(s) to load in the `tf.data.Dataset`.\\\\n\\\\t\\\\tColumn names that are created by the `collate_fn` and that do not exist in the original dataset can be used.\\\\n\\\\tshuffle(`bool`, defaults to `False`):\\\\n\\\\t\\\\tShuffle the dataset order when loading. Recommended `True` for training, `False` for\\\\n\\\\t\\\\tvalidation/evaluation.\\\\n\\\\tdrop_remainder(`bool`, defaults to `False`):\\\\n\\\\t\\\\tDrop the last incomplete batch when loading. Ensures\\\\n\\\\t\\\\tthat all batches yielded by the dataset will have the same length on the batch dimension.\\\\n\\\\tcollate_fn(`Callable`, *optional*):\\\\n\\\\t\\\\tA function or callable object (such as a `DataCollator`) that will collate\\\\n\\\\t\\\\tlists of samples into a batch.\\\\n\\\\tcollate_fn_args (`Dict`, *optional*):\\\\n\\\\t\\\\tAn optional `dict` of keyword arguments to be passed to the\\\\n\\\\t\\\\t`collate_fn`.\\\\n\\\\tlabel_cols (`List[str]` or `str`, defaults to `None`):\\\\n\\\\t\\\\tDataset column(s) to load as labels.\\\\n\\\\t\\\\tNote that many models compute loss internally rather than letting Keras do it, in which case\\\\n\\\\t\\\\tpassing the labels here is optional, as long as they\'re in the input `columns`.\\\\n\\\\tprefetch (`bool`, defaults to `True`):\\\\n\\\\t\\\\tWhether to run the dataloader in a separate thread and maintain\\\\n\\\\t\\\\ta small buffer of batches for training. Improves performance by allowing data to be loaded in the\\\\n\\\\t\\\\tbackground while the model is training.\\\\n\\\\tnum_workers (`int`, defaults to `0`):\\\\n\\\\t\\\\tNumber of workers to use for loading the dataset.\\\\n\\\\tnum_test_batches (`int`, defaults to `20`):\\\\n\\\\t\\\\tNumber of batches to use to infer the output signature of the dataset.\\\\n\\\\t\\\\tThe higher this number, the more accurate the signature will be, but the longer it will take to\\\\n\\\\t\\\\tcreate the dataset.\\\\n\\\\nReturns:\\\\n\\\\t`tf.data.Dataset`: Dataset class from the TensorFlow library.", "class_TensorflowDatasetMixin_method_save_to_cache": "Saves the current dataset to the cache directory.\\\\n\\\\nReturns:\\\\n\\\\tstr: Path where dataset was saved.\\\\n\\\\nRaises:\\\\n\\\\tValueError: If neither cache_dir nor name is set.", "class_DatasetTransformationNotAllowedError": "", "function__check_column_names": "Check the column names to make sure they don\'t contain duplicates.\\\\n\\\\nArgs:\\\\n\\\\tcolumn_names (`list[str]`):\\\\n\\\\t\\\\tList of column names.\\\\n\\\\nReturns:\\\\n\\\\tNone", "function__concatenate_map_style_datasets": "Converts a list of :class:`Dataset` with the same schema into a single :class:`Dataset`.\\\\nWhen you concatenate on axis 0, missing data are filled with None values.\\\\n\\\\nArgs:\\\\n\\\\tdsets (`List[datasets.Dataset]`):\\\\n\\\\t\\\\tList of Datasets to concatenate.\\\\n\\\\tinfo (:class:`DatasetInfo`, optional):\\\\n\\\\t\\\\tDataset information, like description, citation, etc.\\\\n\\\\tsplit (:class:`NamedSplit`, optional):\\\\n\\\\t\\\\tName of the dataset split.\\\\n\\\\taxis (``{0, 1}``, default ``0``, meaning over rows):\\\\n\\\\t\\\\tAxis to concatenate over, where ``0`` means over rows (vertically) and ``1`` means over columns\\\\n\\\\t\\\\t(horizontally).\\\\n\\\\nReturns:\\\\n\\\\t `Dataset`: Dataset, consisting of the input list of datasets.", "function__interleave_map_style_datasets": "Interleave several map-style datasets (sources) into a single map-style dataset.\\\\nThe new dataset is constructed by alternating between the sources to get the examples.\\\\nIf `probabilities = None` (default) the new dataset is constructed by cycling between each source to get the examples.\\\\nIf `probabilities` is not `None, the new dataset is constructed by getting examples from a random source at a time according to the provided probabilities.\\\\n\\\\nArgs:\\\\n\\\\tdatasets (`List[Dataset]`):\\\\n\\\\t\\\\tlist of datasets to interleave\\\\n\\\\tprobabilities (`List[float]`, optional, default None):\\\\n\\\\t\\\\tIf specified, the new dataset is constructed by sampling\\\\n\\\\t\\\\texamples from one source at a time according to these probabilities.\\\\n\\\\tseed (`int`, optional, default None):\\\\n\\\\t\\\\tThe random seed used to choose a source for each example.\\\\n\\\\tinfo (:class:`DatasetInfo`, optional):\\\\n\\\\t\\\\tDataset information, like description, citation, etc.\\\\n\\\\tsplit (:class:`NamedSplit`, optional):\\\\n\\\\t\\\\tName of the dataset split.\\\\n\\\\tstopping_strategy (`str`, defaults to `first_exhausted`):\\\\n\\\\t\\\\tTwo strategies are proposed right now.\\\\n\\\\t\\\\tBy default, `first_exhausted` is an undersampling strategy, i.e the dataset construction is stopped as soon as one dataset has ran out of samples.\\\\n\\\\t\\\\tIf the strategy is `all_exhausted`,  we use an oversampling strategy, i.e the dataset construction is stopped as soon as every samples of every dataset has been added at least once.\\\\n\\\\t\\\\tNote that if the strategy is `all_exhausted`, the interleaved dataset size can get enormous:\\\\n\\\\t\\\\t- with no probabilities, the resulting dataset will have max_length_datasets*nb_dataset samples.\\\\n\\\\t\\\\t- with given probabilities, the resulting dataset will have more samples if some datasets have really low probability of visiting.\\\\n\\\\t**kwargs (additional keyword arguments):\\\\n\\\\t\\\\tKeyword arguments to be passed to :meth:`datasets.Datasets.select` when selecting the indices used to interleave the datasets.\\\\n\\\\nReturns:\\\\n\\\\t`Dataset`: a single map-style dataset, constructed by alternating between the sources to get the examples.", "function__split_by_node_map_style_dataset": "Split a dataset for the node at rank `rank` in a pool of nodes of size `world_size`.\\\\nEach node is assigned a chunk of data, e.g. rank 0 is given the first chunk of the dataset.\\\\nTo maximize data loading throughput, chunks are made of contiguous data on disk if possible.\\\\n\\\\nArgs:\\\\n\\\\tdataset (`Dataset`):\\\\n\\\\t\\\\tThe dataset to split by node.\\\\n\\\\trank (`int`):\\\\n\\\\t\\\\tRank of the current node.\\\\n\\\\tworld_size (`int`):\\\\n\\\\t\\\\tTotal number of nodes.\\\\n\\\\nReturns:\\\\n\\\\t`Dataset`: The dataset to be used on the node at rank `rank`."}\n"""',
    },
    {
        "role": "user",
        "content": "Input code:\n```\nfrom typing import, Any, Dict, Optional, Tuple\n\nimport torch\n\nfrom ..utils import is_sklearn_available\n\n\nif is_sklearn_available():\n    from sklearn.metrics import roc_curve\n\nfrom ..cache_utils import DynamicCache\nfrom ..pytorch_utils import isin_mps_friendly\n\nclass BaseGenerator:\n    def generate(self) -> Any:\n        raise NotImplementedError(\"All generators must implement generate method\")\n\nclass CandidateGenerator(BaseGenerator):\n    \"\"\"Add docstring\"\"\"\n    \n    def get_candidates(self, input_ids: torch.LongTensor) -> Tuple[torch.LongTensor, Optional[torch.FloatTensor]]:\n        raise NotImplementedError(\n            f\"{self.__class__} is an abstract class. Only classes inheriting this class can call `get_candidates`.\"\n        )\n\n    def update_candidate_strategy(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, num_matches: int):\n        raise NotImplementedError(\n            f\"{self.__class__} is an abstract class. Only classes inheriting this class can call \"\n            \"`update_candidate_strategy`.\"\n        )\n\nclass PromptLookupCandidateGenerator(CandidateGenerator):\n    def __init__(\n        self,\n        eos_token_id: torch.Tensor = None,\n        num_output_tokens: int = 10,\n        max_matching_ngram_size: int = None,\n        max_length: int = 20,\n    ):\n        self.num_output_tokens = num_output_tokens\n        self.max_matching_ngram_size = max_matching_ngram_size if max_matching_ngram_size else 2\n        self.max_length = max_length\n        self.eos_token_id = eos_token_id\n\n        if self.max_matching_ngram_size <= 0 or self.num_output_tokens <= 0:\n            raise ValueError(\"Invalid max_matching_ngram_size or num_output_tokens\")\n\n    def get_candidates(self, input_ids: torch.LongTensor) -> Tuple[torch.LongTensor, Optional[torch.FloatTensor]]:\n        input_length = input_ids.size(1)\n\n        # Don't generate more than `max_length - 1` candidates since the target model generates one extra token.\n        if self.max_length == input_length + 1:\n            return input_ids, None\n\n        chosen_ids = None\n        match_found = False\n        for ngram_size in range(min(self.max_matching_ngram_size, input_length - 1), 0, -1):\n            # Create sliding windows of size ngram_size\n            windows = input_ids.unfold(dimension=1, size=ngram_size, step=1)\n\n            # Convert ngram to a tensor for comparison\n            ngram_tensor = input_ids[0, -ngram_size:]\n\n            # Find where the windows match the ngram\n            matches = (windows == ngram_tensor).all(dim=2)\n\n            # Get the indices of matches\n            match_indices = matches.nonzero(as_tuple=True)[1]\n\n            # Iterate through match indices to find a valid continuation\n            for idx in match_indices:\n                start_idx = idx + ngram_size\n                end_idx = start_idx + self.num_output_tokens\n                end_idx = min(end_idx, input_length, self.max_length)\n\n                if start_idx < end_idx:\n                    chosen_ids = input_ids[0, start_idx:end_idx]\n                    match_found = True\n\n                    # remove remaining candidate ids if an \"eos\" token is found, otherwise the target model may\n                    # accept eos and the rest as valid, thus not stopping generation after \"eos\"\n                    # NOTE: below code is written based on the fact that assisted decoding supports only bs=1\n                    mask = isin_mps_friendly(chosen_ids, self.eos_token_id)\n                    match_indices_eos = torch.nonzero(mask)\n                    if match_indices_eos.numel() > 0:\n                        first_eos_index = match_indices_eos[0].item()\n                        chosen_ids = chosen_ids[:first_eos_index]\n                    break\n            if match_found:\n                break\n\n        if chosen_ids is None or len(chosen_ids) == 0:\n            # In case we didn't find a match return the input sequence unchanged, reverts back to autoregressive decoding\n            return input_ids, None\n\n        # Now need extend input_ids with chosen_ids\n        chosen_ids = chosen_ids.unsqueeze(0)\n        candidate_input_ids = torch.cat((input_ids, chosen_ids), dim=1)\n        # assisted_generation expects logits as well, but we don't have those here, so returning None\n        return candidate_input_ids, None\n\n    def update_candidate_strategy(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, num_matches: int):\n        # Currently does nothing, but will be extended in the future\n        return\n\nclass EarlyExitCandidateGenerator(AssistedCandidateGenerator):\n    def __init__(\n        self,\n        input_ids: torch.LongTensor,\n        assistant_model: \"PreTrainedModel\",\n        generation_config: \"GenerationConfig\",\n        model_kwargs: Dict,\n        inputs_tensor: Optional[torch.Tensor] = None,\n        logits_processor: \"LogitsProcessorList\" = None,\n    ):\n        super().__init__(\n            input_ids=input_ids,\n            assistant_model=assistant_model,\n            generation_config=generation_config,\n            model_kwargs=model_kwargs,\n            inputs_tensor=inputs_tensor,\n            logits_processor=logits_processor,\n        )\n        # We have to move early exit out of the generation config, otherwise the assistant will also call `generate`\n        # with early exit\n        self.assistant_early_exit = self.generation_config.assistant_early_exit\n        self.generation_config.assistant_early_exit = None\n\n    def get_candidates(self, input_ids: torch.LongTensor) -> Tuple[torch.LongTensor, Optional[torch.FloatTensor]]:\n        # Temporarily sets the number of hidden layers to the early exit value\n        base_model = getattr(self.assistant_model, self.assistant_model.base_model_prefix)\n        original_num_hidden_layers = base_model.config.num_hidden_layers\n        base_model.config.num_hidden_layers = self.assistant_early_exit\n        candidate_ids, candidate_logits = super().get_candidates(input_ids)\n        base_model.config.num_hidden_layers = original_num_hidden_layers\n        return candidate_ids, candidate_logits\n```\n\nJson schema:\n```\n{'properties': {'class_BaseGenerator': {'description': 'Docstring for the class `BaseGenerator`', 'title': 'Class Basegenerator', 'type': 'string'}, 'class_BaseGenerator_method_generate': {'description': 'Docstring for the method `generate` of the class `BaseGenerator`', 'title': 'Class Basegenerator Method Generate', 'type': 'string'}, 'class_CandidateGenerator': {'description': 'Docstring for the class `CandidateGenerator`', 'title': 'Class Candidategenerator', 'type': 'string'}, 'class_CandidateGenerator_method_get_candidates': {'description': 'Docstring for the method `get_candidates` of the class `CandidateGenerator`', 'title': 'Class Candidategenerator Method Get Candidates', 'type': 'string'}, 'class_CandidateGenerator_method_update_candidate_strategy': {'description': 'Docstring for the method `update_candidate_strategy` of the class `CandidateGenerator`', 'title': 'Class Candidategenerator Method Update Candidate Strategy', 'type': 'string'}, 'class_PromptLookupCandidateGenerator': {'description': 'Docstring for the class `PromptLookupCandidateGenerator`', 'title': 'Class Promptlookupcandidategenerator', 'type': 'string'}, 'class_PromptLookupCandidateGenerator_method___init__': {'description': 'Docstring for the method `__init__` of the class `PromptLookupCandidateGenerator`', 'title': 'Class Promptlookupcandidategenerator Method   Init  ', 'type': 'string'}, 'class_PromptLookupCandidateGenerator_method_get_candidates': {'description': 'Docstring for the method `get_candidates` of the class `PromptLookupCandidateGenerator`', 'title': 'Class Promptlookupcandidategenerator Method Get Candidates', 'type': 'string'}, 'class_PromptLookupCandidateGenerator_method_update_candidate_strategy': {'description': 'Docstring for the method `update_candidate_strategy` of the class `PromptLookupCandidateGenerator`', 'title': 'Class Promptlookupcandidategenerator Method Update Candidate Strategy', 'type': 'string'}, 'class_EarlyExitCandidateGenerator': {'description': 'Docstring for the class `EarlyExitCandidateGenerator`', 'title': 'Class Earlyexitcandidategenerator', 'type': 'string'}, 'class_EarlyExitCandidateGenerator_method___init__': {'description': 'Docstring for the method `__init__` of the class `EarlyExitCandidateGenerator`', 'title': 'Class Earlyexitcandidategenerator Method   Init  ', 'type': 'string'}, 'class_EarlyExitCandidateGenerator_method_get_candidates': {'description': 'Docstring for the method `get_candidates` of the class `EarlyExitCandidateGenerator`', 'title': 'Class Earlyexitcandidategenerator Method Get Candidates', 'type': 'string'}}, 'required': ['class_BaseGenerator', 'class_BaseGenerator_method_generate', 'class_CandidateGenerator', 'class_CandidateGenerator_method_get_candidates', 'class_CandidateGenerator_method_update_candidate_strategy', 'class_PromptLookupCandidateGenerator', 'class_PromptLookupCandidateGenerator_method___init__', 'class_PromptLookupCandidateGenerator_method_get_candidates', 'class_PromptLookupCandidateGenerator_method_update_candidate_strategy', 'class_EarlyExitCandidateGenerator', 'class_EarlyExitCandidateGenerator_method___init__', 'class_EarlyExitCandidateGenerator_method_get_candidates'], 'title': 'DocstringModel', 'type': 'object'}```",
    },
    {
        "role": "assistant",
        "content": '"""\n{"class_BaseGenerator": "", "class_BaseGenerator_method_generate": "", "class_CandidateGenerator": "Abstract base class for all candidate generators that can be applied during assisted generation.", "class_CandidateGenerator_method_get_candidates": "Fetches the candidates to be tried for the current input.\\\\n\\\\nArgs:\\\\n\\\\tinput_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\\\\n\\\\t\\\\tIndices of input sequence tokens in the vocabulary.\\\\n\\\\nReturn:\\\\n\\\\t`torch.LongTensor` of shape `(batch_size, candidate_length)` containing the candidate sequences to be\\\\n\\\\tassessed by the model and, optionally, a `torch.FloatTensor` of shape `(batch_size, candidate_length,\\\\n\\\\tvocabulary_size)` containing the logits associated to each candidate.", "class_CandidateGenerator_method_update_candidate_strategy": "Updates the candidate generation strategy based on the outcomes.\\\\n\\\\nArgs:\\\\n\\\\tinput_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\\\\n\\\\t\\\\tIndices of input sequence tokens in the vocabulary.\\\\n\\\\tscores (`torch.FloatTensor` of shape `(batch_size, candidate_length, config.vocab_size)`):\\\\n\\\\t\\\\tPrediction scores of a language modeling head. These can be logits for each vocabulary when not using\\\\n\\\\t\\\\tbeam search or log softmax for each vocabulary token when using beam search\\\\n\\\\tnum_matches (`int`):\\\\n\\\\t\\\\tThe number of matches between the candidate sequences and the model predictions.", "class_PromptLookupCandidateGenerator": "`CandidateGenerator` class to be used for prompt lookup generation. This class generates candidates by looking up\\\\nlikely continuations in the provided prompt (input_ids) itself.\\\\nArgs:\\\\n\\\\tmax_matching_ngram_size (`int`):\\\\n\\\\t\\\\tThe maximum ngram size to be considered for matching in the prompt\\\\n\\\\tnum_output_tokens (`int`):\\\\n\\\\t\\\\tThe number of tokens to be output as candidate tokens.\\\\n\\\\tmax_length (`int`):\\\\n\\\\t\\\\tThe number of total maximum tokens that can be generated. For decoder-only models that includes the prompt length.\\\\n\\\\t\\\\tDefaults to 20, which is the max length used as default in generation config.", "class_PromptLookupCandidateGenerator_method___init__": "", "class_PromptLookupCandidateGenerator_method_get_candidates": "Fetches the candidates to be tried for the current input.\\\\n\\\\nArgs:\\\\n\\\\tinput_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\\\\n\\\\t\\\\tIndices of input sequence tokens in the vocabulary.\\\\n\\\\nReturn:\\\\n\\\\t`torch.LongTensor` of shape `(num_candidates, candidate_length)`: The candidate sequences to be tried.", "class_PromptLookupCandidateGenerator_method_update_candidate_strategy": "Updates the candidate generation strategy based on the outcomes.\\\\n\\\\nArgs:\\\\n\\\\tinput_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\\\\n\\\\t\\\\tIndices of input sequence tokens in the vocabulary.\\\\n\\\\tscores (`torch.FloatTensor` of shape `(batch_size, candidate_length, config.vocab_size)`):\\\\n\\\\t\\\\tPrediction scores of a language modeling head. These can be logits for each vocabulary when not using\\\\n\\\\t\\\\tbeam search or log softmax for each vocabulary token when using beam search\\\\n\\\\tnum_matches (`int`):\\\\n\\\\t\\\\tThe number of matches between the candidate sequences and the model predictions.", "class_EarlyExitCandidateGenerator": "`CandidateGenerator` class to be used for assisted generation and speculative decoding. This class generates\\\\ncandidates through the use of **the model itself**, exiting early.\\\\n\\\\nArgs:\\\\n\\\\tinput_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\\\\n\\\\t\\\\tIndices of input sequence tokens in the vocabulary.\\\\n\\\\tassistant_model (`PreTrainedModel`):\\\\n\\\\t\\\\tThe original model. This model must support early exit (i.e. is trained to compute logits in earlier\\\\n\\\\t\\\\tlayers).\\\\n\\\\tgeneration_config (`~generation.GenerationConfig`, *optional*):\\\\n\\\\t\\\\tThe generation configuration to be used as base parametrization for the generation call.\\\\n\\\\tlogits_processor (`LogitsProcessorList`):\\\\n\\\\t\\\\tAn instance of `LogitsProcessorList`. List of instances of class derived from `LogitsProcessor`\\\\n\\\\t\\\\tused to modify the prediction scores of the language modeling head applied at each generation step.\\\\n\\\\tmodel_kwargs (`Dict`):\\\\n\\\\t\\\\tThe keyword arguments that will be passed to the main model, and are used as base inputs for the assistant\\\\n\\\\t\\\\tmodel as well.\\\\n\\\\tinputs_tensor (`torch.Tensor`, *optional*):\\\\n\\\\t\\\\tThe model input tensor. In encoder-decoder models, this is the encoder input.", "class_EarlyExitCandidateGenerator_method___init__": "", "class_EarlyExitCandidateGenerator_method_get_candidates": "Fetches the candidates to be tried for the current input.\\\\n\\\\nArgs:\\\\n\\\\tinput_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\\\\n\\\\t\\\\tIndices of input sequence tokens in the vocabulary.\\\\n\\\\nReturn:\\\\n\\\\t`torch.LongTensor` of shape `(batch_size, candidate_length)` containing the candidate sequences to be\\\\n\\\\tassessed by the model and a `torch.FloatTensor` of shape `(batch_size, candidate_length,\\\\n\\\\tvocabulary_size)` containing the logits associated to each candidate."}\n"""',
    },
    {
        "role": "user",
        "content": "Input code:\n```\nfrom typing import Union, Any, Optional, NamedTuple\n\nclass BestRun(NamedTuple):\n    \"\"\"best run of hyperparameter search.\n    \"\"\"\n\n    run_id: str\n    objective: Union[float, list[float]]\n    hyperparameters: dict[str, Any]\n    run_summary: Optional[Any] = None\n```\n\nJson schema:\n```\n{'properties': {'class_BestRun': {'description': 'Docstring for the class `BestRun`', 'title': 'Class Bestrun', 'type': 'string'}}, 'required': ['class_BestRun'], 'title': 'DocstringModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '"""\n{"class_BestRun": "The best run found by a hyperparameter search.\\\\n\\\\nArgs:\\\\n\\\\trun_id (`str`):\\\\n\\\\t\\\\tThe id of the best run.\\\\n\\\\tobjective (`Union[float, list[float]`):\\\\n\\\\t\\\\tThe objective value or list of objectives values obtained for this run.\\\\n\\\\thyperparameters (`dict[str, Any]`):\\\\n\\\\t\\\\tThe hyperparameters used to get this run.\\\\n\\\\trun_summary (`Optional[Any]`):\\\\n\\\\t\\\\tThe summary of tuning experiments."}\n"""',
    },
    {
        "role": "user",
        "content": "Input code:\n```\ndef _create_4d_causal_attention_mask(\n    input_shape: Union[torch.Size, Tuple, List],\n    dtype: torch.dtype,\n    device: torch.device,\n    past_key_values_length: int = 0,\n    sliding_window: Optional[int] = None,\n) -> Optional[torch.Tensor]:\n    attn_mask_converter = AttentionMaskConverter(is_causal=True, sliding_window=sliding_window)\n\n    key_value_length = past_key_values_length + input_shape[-1]\n    attention_mask = attn_mask_converter.to_causal_4d(\n        input_shape[0], input_shape[-1], key_value_length, dtype=dtype, device=device\n    )\n\n    return attention_mask\n```\n\nJson schema:\n```\n{'properties': {'function__create_4d_causal_attention_mask': {'description': 'Docstring for the function `_create_4d_causal_attention_mask`', 'title': 'Function  Create 4D Causal Attention Mask', 'type': 'string'}}, 'required': ['function__create_4d_causal_attention_mask'], 'title': 'FunctionsDocstringModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '"""\n{"function__create_4d_causal_attention_mask": "Creates a causal 4D mask of shape `(batch_size, 1, query_length, key_value_length)`\\\\n\\\\nArgs:\\\\n\\\\\\\\tinput_shape (`tuple(int)` or `list(int)` or `torch.Size`):\\\\n\\\\\\\\t\\\\\\\\tThe input shape should be a tuple that defines `(batch_size, query_length)`.\\\\n\\\\\\\\tdtype (`torch.dtype`):\\\\n\\\\\\\\t\\\\\\\\tThe torch dtype the created mask shall have.\\\\n\\\\\\\\tdevice (`int`):\\\\n\\\\\\\\t\\\\\\\\tThe torch device the created mask shall have.\\\\n\\\\\\\\tsliding_window (`int`, *optional*):\\\\n\\\\\\\\t\\\\\\\\tIf the model uses windowed attention, a sliding window should be passed."}\n"""',
    },
    {
        "role": "user",
        "content": "Input code:\n```\nimport dataclasses\nimport json\nfrom dataclasses import dataclass\nfrom typing import Optional, Union\n\n@dataclass\nclass TrainerState:\n    is_world_process_zero: bool = False\n    epoch: int = 0\n    global_step: int = 0\n    best_model_score: float = float('inf')\n    improvement_threshold: float = 1e-4\n    inner_flag_matrix: dict[str, list[Union[bool, Optional[int]]]] = None\n\n    def __post_init__(self):\n        if self.inner_flag_matrix is None:\n            self.inner_flag_matrix = {}\n\n    def update_best_score(self, new_score: float) -> bool:\n        if (self.best_model_score - new_score) > self.improvement_threshold:\n            self.best_model_score = new_score\n            return True\n        return False\n\n    def save_to_json(self, json_path: str):\n        \"\"\"Saves the content of this instance inside `json_path`.\"\"\"\n        json_string = json.dumps(dataclasses.asdict(self), indent=2, sort_keys=True) + \"\\n\"\n        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(json_string)\n\n    @classmethod\n    def load_from_json(cls, json_path: str):\n        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n            text = f.read()\n        return cls(**json.loads(text))\n```\n\nJson schema:\n```\n{'properties': {'class_TrainerState': {'description': 'Docstring for the class `TrainerState`', 'title': 'Class Trainerstate', 'type': 'string'}, 'class_TrainerState_method___post_init__': {'description': 'Docstring for the method `__post_init__` of the class `TrainerState`', 'title': 'Class Trainerstate Method   Post Init  ', 'type': 'string'}, 'class_TrainerState_method_update_best_score': {'description': 'Docstring for the method `update_best_score` of the class `TrainerState`', 'title': 'Class Trainerstate Method Update Best Score', 'type': 'string'}, 'class_TrainerState_method_save_to_json': {'description': 'Docstring for the method `save_to_json` of the class `TrainerState`', 'title': 'Class Trainerstate Method Save To Json', 'type': 'string'}, 'class_TrainerState_method_load_from_json': {'description': 'Docstring for the method `load_from_json` of the class `TrainerState`', 'title': 'Class Trainerstate Method Load From Json', 'type': 'string'}}, 'required': ['class_TrainerState', 'class_TrainerState_method___post_init__', 'class_TrainerState_method_update_best_score', 'class_TrainerState_method_save_to_json', 'class_TrainerState_method_load_from_json'], 'title': 'DocstringModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '"""\n{"class_TrainerState": "Class to track the state of a model training process.\\\\n\\\\nArgs:\\\\n\\\\tis_world_process_zero (`bool`)\\\\n\\\\tepoch (`int`):\\\\n\\\\t\\\\tCurrent epoch number during training\\\\n\\\\tglobal_step (`int`):\\\\n\\\\t\\\\tTotal number of training steps performed\\\\n\\\\tbest_model_score (`float`):\\\\n\\\\t\\\\tBest validation score achieved during training\\\\n\\\\timprovement_threshold (`float`):\\\\n\\\\t\\\\tMinimum difference required to consider a new score as an improvement\\\\n\\\\t\\\\t(helps avoid updating on insignificant improvements)\\\\n\\\\tinner_flag_matrix (`dict[str, list[Union[bool, Optional[int]]]]`)", "class_TrainerState_method___post_init__": "", "class_TrainerState_method_update_best_score": "Updates best_model_score if the new score is better (lower) by at least improvement_threshold.\\\\n\\\\nArgs:\\\\n\\\\tnew_score (`float`):\\\\n\\\\t\\\\tNew score to compare against the best score.\\\\n\\\\t\\\\nReturns:\\\\n\\\\t`bool`: True if the new score is better by at least `improvement_threshold`, False otherwise", "class_TrainerState_method_save_to_json": "Save the content of this instance in JSON format inside `json_path`.\\\\n\\\\nArgs:\\\\n\\\\tjson_path (`str`):\\\\n\\\\t\\\\tPath to the JSON file in which this instance is saved.\\\\nReturns:\\\\n\\\\tNone (saves the content in JSON format)", "class_TrainerState_method_load_from_json": "Create an instance of `TrainerState` from the content of `json_path`.\\\\n\\\\nArgs:\\\\n\\\\tjson_path (`str`):\\\\n\\\\t\\\\tPath to the JSON file that will be used to recreate the instance.\\\\n\\\\nReturns:\\\\n\\\\t`TrainerState` from the content of `json_path` file."}\n"""',
    },
    {
        "role": "user",
        "content": "Input code:\n```\nimport numpy as np\nfrom sacrebleu.metrics import BLEU\n\nfrom typing import List, Dict\nfrom .generation_metric import GenerationMetric\n\n\nclass BLEUMetric(GenerationMetric):\n    def __init__(self):\n        super().__init__([\"greedy_texts\"], \"sequence\")\n        self.scorer = BLEU(effective_order=True, lowercase=True)\n\n    def __str__(self):\n        return \"BLEU\"\n\n    def _score_single(self, t1: str, t2: str):\n        return self.scorer.sentence_score(\n            t1.strip().rstrip(\".\"), [t2.strip().rstrip(\".\")]\n        ).score\n\n    def __call__(\n        self,\n        stats: Dict[str, np.ndarray],\n        target_texts: List[str],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculates BLEU score between stats['greedy_texts'] and target_texts.\n        \"\"\"\n        return np.array(\n            [\n                self._score_single(hyp, ref)\n                for hyp, ref in zip(stats[\"greedy_texts\"], target_texts)\n            ]\n        )\n```\n\nJson schema:\n```\n{'properties': {'class_BLEUMetric': {'description': 'Docstring for the class `BLEUMetric`', 'title': 'Class Bleumetric', 'type': 'string'}, 'class_BLEUMetric_method___init__': {'description': 'Docstring for the method `__init__` of the class `BLEUMetric`', 'title': 'Class Bleumetric Method   Init  ', 'type': 'string'}, 'class_BLEUMetric_method___str__': {'description': 'Docstring for the method `__str__` of the class `BLEUMetric`', 'title': 'Class Bleumetric Method   Str  ', 'type': 'string'}, 'class_BLEUMetric_method__score_single': {'description': 'Docstring for the method `_score_single` of the class `BLEUMetric`', 'title': 'Class Bleumetric Method  Score Single', 'type': 'string'}, 'class_BLEUMetric_method___call__': {'description': 'Docstring for the method `__call__` of the class `BLEUMetric`', 'title': 'Class Bleumetric Method   Call  ', 'type': 'string'}}, 'required': ['class_BLEUMetric', 'class_BLEUMetric_method___init__', 'class_BLEUMetric_method___str__', 'class_BLEUMetric_method__score_single', 'class_BLEUMetric_method___call__'], 'title': 'DocstringModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '"""\n{"class_BLEUMetric": "A class for calculating the BLEU (Bilingual Evaluation Understudy) score, which is a metric for evaluating the quality of text generated by a machine translation system compared to a reference translation.\\\\n\\\\nThe BLEUMetric class inherits from the GenerationMetric class and is specifically designed to compute BLEU scores between model-generated texts and ground-truth texts.\\\\n\\\\nArgs:\\\\n\\\\tscorer (`BLEU`): An instance of the BLEU scorer from the sacrebleu library, configured with effective order and lowercase options.\\\\n\\\\nMethods:\\\\n\\\\t__init__(): Initializes the BLEUMetric object with the necessary attributes.\\\\n\\\\t__str__(): Returns the string representation of the metric, which is \'BLEU\'.\\\\n\\\\t_score_single(t1: str, t2: str): Computes the BLEU score for a single pair of hypothesis and reference texts.\\\\n\\\\t__call__(stats: Dict[str, np.ndarray], target_texts: List[str]) -> np.ndarray: Calculates BLEU scores for multiple samples by comparing the model-generated texts in `stats[\'greedy_texts\']` \\\\n\\\\twith the ground-truth texts in `target_texts`.", "class_BLEUMetric_method___init__": "", "class_BLEUMetric_method___str__": "", "class_BLEUMetric_method__score_single": "", "class_BLEUMetric_method___call__": "Calculates the BLEU score between `stats[\'greedy_texts\']` and `target_texts`.\\\\n\\\\nArgs:\\\\n\\\\tstats (`dict[str, np.ndarray]`):\\\\n\\\\t\\\\tinput statistics, which for multiple samples includes: * model-generated texts in \'greedy_texts\'\\\\n\\\\ttarget_texts (`list[str]`):\\\\n\\\\t\\\\tground-truth texts\\\\nReturns:\\\\n\\\\t`np.ndarray` with BLEU Scores for each sample in input."}\n"""',
    },
]

MESSAGES_DOCSTRING_ADDITION = [
    {
        "role": "user",
        "content": "Input code:\n```\nimport math\nfrom numbers import Real\n\nimport numpy as np\nfrom scipy.special import betaln, digamma, gammaln\n\n\ndef _log_dirichlet_norm(dirichlet_concentration):\n    return gammaln(np.sum(dirichlet_concentration)) - np.sum(\n        gammaln(dirichlet_concentration)\n    )\n\n\ndef _log_wishart_norm(degrees_of_freedom, log_det_precisions_chol, n_features):\n    \"\"\"Compute log Wishart distribution normalization term.\n\n    Parameters\n    ----------\n    degrees_of_freedom : array-like of shape (n_components,)\n    log_det_precision_chol : array-like of shape (n_components,)\n    n_features : int\n\n    Return\n    ------\n    log_wishart_norm : array-like of shape (n_components,)\n    \"\"\"\n    # To simplify the computation we have removed the np.log(np.pi) term\n    return -(\n        degrees_of_freedom * log_det_precisions_chol\n        + degrees_of_freedom * n_features * 0.5 * math.log(2.0)\n        + np.sum(\n            gammaln(0.5 * (degrees_of_freedom - np.arange(n_features)[:, np.newaxis])),\n            0,\n        )\n    )\n```\n\nJson schema:\n```\n{'properties': {'function__log_dirichlet_norm': {'description': 'Docstring for the function `_log_dirichlet_norm`', 'title': 'Function  Log Dirichlet Norm', 'type': 'string'}, 'function__log_wishart_norm': {'description': 'Docstring for the function `_log_wishart_norm`', 'title': 'Function  Log Wishart Norm', 'type': 'string'}}, 'required': ['function__log_dirichlet_norm', 'function__log_wishart_norm'], 'title': 'DocstringModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '"""\n{"function__log_dirichlet_norm": "Compute the log of the Dirichlet distribution normalization term.\\\\n\\\\nArgs:\\\\n\\\\tdirichlet_concentration (`np.ndarray`):\\\\n\\\\t\\\\tThe parameters values of the Dirichlet distribution.\\\\n\\\\nReturns:\\\\n\\\\t`float`: The log normalization of the Dirichlet distribution.", "function__log_wishart_norm": "Compute the log of the Wishart distribution normalization term.\\\\n\\\\nArgs:\\\\n\\\\tdegrees_of_freedom (`np.ndarray`):\\\\n\\\\t\\\\tThe number of degrees of freedom on the covariance Wishart distributions.\\\\n\\\\t\\\\n\\\\tlog_det_precision_chol (`np.ndarray`):\\\\n\\\\t\\\\t The determinant of the precision matrix for each component.\\\\n\\\\t\\\\n\\\\tn_features (`int`):\\\\n\\\\t\\\\tThe number of features.\\\\n\\\\nReturns:\\\\n\\\\t`np.ndarray`: The log normalization of the Wishart distribution."}\n"""',
    },
    {
        "role": "user",
        "content": "Input code:\n```\nclass IterableDatasetDict(dict):\n    def __repr__(self):\n        repr = \"\\n\".join([f\"{k}: {v}\" for k, v in self.items()])\n        repr = re.sub(r\"^\", \" \" * 4, repr, 0, re.M)\n        return f\"IterableDatasetDict({{\\n{repr}\\n}})\"\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        # Here `del` is used to del the pyarrow tables. This properly closes the files used for memory mapped tables\n        for dataset in self.values():\n            if hasattr(dataset, \"_data\"):\n                del dataset._data\n            if hasattr(dataset, \"_indices\"):\n                del dataset._indices\n\n    @property\n    def data(self) -> dict[str, Table]:\n        self._check_values_type()\n        return {k: dataset.data for k, dataset in self.items()}\n\n    def rename_column(self, original_column_name: str, new_column_name: str) -> \"IterableDatasetDict\":\n        \"\"\"Rename column in dataset\"\"\"\n        return IterableDatasetDict(\n            {\n                k: dataset.rename_column(original_column_name=original_column_name, new_column_name=new_column_name)\n                for k, dataset in self.items()\n            }\n        )\n\n    def rename_columns(self, column_mapping: Dict[str, str]) -> \"IterableDatasetDict\":\n\n        return IterableDatasetDict(\n            {k: dataset.rename_columns(column_mapping=column_mapping) for k, dataset in self.items()}\n        )\n\n    def remove_columns(self, column_names: Union[str, List[str]]) -> \"IterableDatasetDict\":\n        \"\"\"\n        Remove one or several column(s) in the dataset and the features associated to them.\n        The removal is done on-the-fly on the examples when iterating over the dataset.\n        The removal is applied to all the datasets of the dataset dictionary.\n        \"\"\"\n        return IterableDatasetDict({k: dataset.remove_columns(column_names) for k, dataset in self.items()})\n\n    def select_columns(self, column_names: Union[str, List[str]]) -> \"IterableDatasetDict\":\n        \"\"\"Select one or several column(s) in the dataset and the features\n        associated to them. The selection is done on-the-fly on the examples\n        when iterating over the dataset. The selection is applied to all the\n        datasets of the dataset dictionary.\n        Args:\n            column_names (`Union[str, list[str]]`)\n        \"\"\"\n        return IterableDatasetDict({k: dataset.select_columns(column_names) for k, dataset in self.items()})\n\n    def cast(\n        self,\n        features: Features,\n    ) -> \"IterableDatasetDict\":\n        return IterableDatasetDict({k: dataset.cast(features=features) for k, dataset in self.items()})\n\n    def shuffle(\n        self, seed=None, generator: Optional[np.random.Generator] = None, buffer_size: int = 1000\n    ) -> \"IterableDatasetDict\":\n        \"\"\"\n        Shufles values of inner datasets\n        \n        seed (`int`, *optional*, defaults to `None`):\n            Random seed that will be used to shuffle the dataset.\n            It is used to sample from the shuffle buffer and also to shuffle the data shards.\n        generator (`numpy.random.Generator`, *optional*):\n            Numpy random Generator to use to compute the permutation of the dataset rows.\n            If `generator=None` (default), uses `np.random.default_rng` (the default BitGenerator (PCG64) of NumPy).\n        buffer_size (`int`, defaults to `1000`):\n            Size of the buffer.\n        \"\"\"\n        return IterableDatasetDict(\n            {\n                k: dataset.shuffle(seed=seed, generator=generator, buffer_size=buffer_size)\n                for k, dataset in self.items()\n            }\n        )\n```\n\nJson schema:\n```\n{'properties': {'class_IterableDatasetDict': {'description': 'Docstring for the class `IterableDatasetDict`', 'title': 'Class Iterabledatasetdict', 'type': 'string'}, 'class_IterableDatasetDict_method___repr__': {'description': 'Docstring for the method `__repr__` of the class `IterableDatasetDict`', 'title': 'Class Iterabledatasetdict Method   Repr  ', 'type': 'string'}, 'class_IterableDatasetDict_method___enter__': {'description': 'Docstring for the method `__enter__` of the class `IterableDatasetDict`', 'title': 'Class Iterabledatasetdict Method   Enter  ', 'type': 'string'}, 'class_IterableDatasetDict_method___exit__': {'description': 'Docstring for the method `__exit__` of the class `IterableDatasetDict`', 'title': 'Class Iterabledatasetdict Method   Exit  ', 'type': 'string'}, 'class_IterableDatasetDict_method_data': {'description': 'Docstring for the method `data` of the class `IterableDatasetDict`', 'title': 'Class Iterabledatasetdict Method Data', 'type': 'string'}, 'class_IterableDatasetDict_method_rename_column': {'description': 'Docstring for the method `rename_column` of the class `IterableDatasetDict`', 'title': 'Class Iterabledatasetdict Method Rename Column', 'type': 'string'}, 'class_IterableDatasetDict_method_rename_columns': {'description': 'Docstring for the method `rename_columns` of the class `IterableDatasetDict`', 'title': 'Class Iterabledatasetdict Method Rename Columns', 'type': 'string'}, 'class_IterableDatasetDict_method_remove_columns': {'description': 'Docstring for the method `remove_columns` of the class `IterableDatasetDict`', 'title': 'Class Iterabledatasetdict Method Remove Columns', 'type': 'string'}, 'class_IterableDatasetDict_method_select_columns': {'description': 'Docstring for the method `select_columns` of the class `IterableDatasetDict`', 'title': 'Class Iterabledatasetdict Method Select Columns', 'type': 'string'}, 'class_IterableDatasetDict_method_cast': {'description': 'Docstring for the method `cast` of the class `IterableDatasetDict`', 'title': 'Class Iterabledatasetdict Method Cast', 'type': 'string'}, 'class_IterableDatasetDict_method_shuffle': {'description': 'Docstring for the method `shuffle` of the class `IterableDatasetDict`', 'title': 'Class Iterabledatasetdict Method Shuffle', 'type': 'string'}}, 'required': ['class_IterableDatasetDict', 'class_IterableDatasetDict_method___repr__', 'class_IterableDatasetDict_method___enter__', 'class_IterableDatasetDict_method___exit__', 'class_IterableDatasetDict_method_data', 'class_IterableDatasetDict_method_rename_column', 'class_IterableDatasetDict_method_rename_columns', 'class_IterableDatasetDict_method_remove_columns', 'class_IterableDatasetDict_method_select_columns', 'class_IterableDatasetDict_method_cast', 'class_IterableDatasetDict_method_shuffle'], 'title': 'DocstringModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '"""\n{"class_IterableDatasetDict": "A dictionary-like class that holds multiple `IterableDataset` objects. This class provides methods to manipulate the datasets collectively, such as renaming columns, removing columns, casting features, and shuffling the data.\\\\n\\\\nMethods:\\\\n\\\\t`__repr__()`: Returns a string representation of the `IterableDatasetDict`.\\\\n\\\\t`rename_column(original_column_name: str, new_column_name: str)`: Renames a column in all datasets.\\\\n\\\\t`rename_columns(column_mapping: Dict[str, str])`: Renames multiple columns in all datasets.\\\\n\\\\t`remove_columns(column_names: Union[str, List[str]])`: Removes specified columns from all datasets.\\\\n\\\\t`select_columns(column_names: Union[str, List[str]])`: Selects specified columns in all datasets.\\\\n\\\\t`cast(features: Features)`: Casts the features of all datasets.\\\\n\\\\t`shuffle(seed=None, generator: Optional[np.random.Generator] = None, buffer_size: int = 1000)`: Shuffles the data in all datasets.", "class_IterableDatasetDict_method___repr__": "", "class_IterableDatasetDict_method___enter__": "", "class_IterableDatasetDict_method___exit__": "", "class_IterableDatasetDict_method_data": "The Apache Arrow tables backing each split.\\\\n\\\\nReturns:\\\\n\\\\t`dict[str, Table]`: A dictionary mapping split names to their corresponding Arrow tables.", "class_IterableDatasetDict_method_rename_column": "Rename a column in the dataset, and move the features associated to the original column under the new column\\\\nname.\\\\nThe renaming is applied to all the datasets of the dataset dictionary.\\\\n\\\\nArgs:\\\\n\\\\toriginal_column_name (`str`):\\\\n\\\\t\\\\tName of the column to rename.\\\\n\\\\tnew_column_name (`str`):\\\\n\\\\t\\\\tNew name for the column.\\\\n\\\\nReturns:\\\\n\\\\t`IterableDatasetDict`: A copy of the dataset with a renamed column.", "class_IterableDatasetDict_method_rename_columns": "Rename several columns in the dataset, and move the features associated to the original columns under\\\\nthe new column names.\\\\nThe renaming is applied to all the datasets of the dataset dictionary.\\\\n\\\\nArgs:\\\\n\\\\tcolumn_mapping (`dict[str, str]`):\\\\n\\\\t\\\\tA mapping of columns to rename to their new names.\\\\n\\\\nReturns:\\\\n\\\\t`IterableDatasetDict`: A copy of the dataset with renamed columns", "class_IterableDatasetDict_method_remove_columns": "Remove one or several column(s) in the dataset and the features associated to them.\\\\nThe removal is done on-the-fly on the examples when iterating over the dataset.\\\\nThe removal is applied to all the datasets of the dataset dictionary.\\\\n\\\\nArgs:\\\\n\\\\tcolumn_names (`Union[str, list[str]]`):\\\\n\\\\t\\\\tName of the column(s) to remove.\\\\n\\\\nReturns:\\\\n\\\\t`IterableDatasetDict`: A copy of the dataset object without the columns to remove.", "class_IterableDatasetDict_method_select_columns": "Select one or several column(s) in the dataset and the features\\\\n\\\\tassociated to them. The selection is done on-the-fly on the examples\\\\n\\\\twhen iterating over the dataset. The selection is applied to all the\\\\n\\\\tdatasets of the dataset dictionary.\\\\n\\\\n\\\\tArgs:\\\\n\\\\t\\\\tcolumn_names (`Union[str, list[str]]`):\\\\n\\\\t\\\\t\\\\tName of the column(s) to keep.\\\\n\\\\n\\\\tReturns:\\\\n\\\\t\\\\t`IterableDatasetDict`: A copy of the dataset object with only selected columns.", "class_IterableDatasetDict_method_cast": "Cast the dataset to a new set of features.\\\\nThe type casting is applied to all the datasets of the dataset dictionary.\\\\n\\\\nArgs:\\\\n\\\\tfeatures (`Features`):\\\\n\\\\t\\\\tNew features to cast the dataset to.\\\\n\\\\t\\\\tThe name of the fields in the features must match the current column names.\\\\n\\\\t\\\\tThe type of the data must also be convertible from one type to the other.\\\\n\\\\t\\\\tFor non-trivial conversion, e.g. `string` <-> `ClassLabel` you should use [`map`] to update the Dataset.\\\\n\\\\nReturns:\\\\n\\\\t`IterableDatasetDict`: A copy of the dataset with casted features.", "class_IterableDatasetDict_method_shuffle": "Randomly shuffles the elements of this dataset.\\\\nThe shuffling is applied to all the datasets of the dataset dictionary.\\\\n\\\\nThis dataset fills a buffer with buffer_size elements, then randomly samples elements from this buffer,\\\\nreplacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or\\\\nequal to the full size of the dataset is required.\\\\n\\\\nFor instance, if your dataset contains 10,000 elements but `buffer_size` is set to 1000, then `shuffle` will\\\\ninitially select a random element from only the first 1000 elements in the buffer. Once an element is\\\\nselected, its space in the buffer is replaced by the next (i.e. 1,001-st) element,\\\\nmaintaining the 1000 element buffer.\\\\n\\\\nArgs:\\\\n\\\\tseed (`int`, *optional*, defaults to `None`):\\\\n\\\\t\\\\tRandom seed that will be used to shuffle the dataset.\\\\n\\\\t\\\\tIt is used to sample from the shuffle buffer and also to shuffle the data shards.\\\\n\\\\tgenerator (`numpy.random.Generator`, *optional*):\\\\n\\\\t\\\\tNumpy random Generator to use to compute the permutation of the dataset rows.\\\\n\\\\t\\\\tIf `generator=None` (default), uses `np.random.default_rng` (the default BitGenerator (PCG64) of NumPy).\\\\n\\\\tbuffer_size (`int`, defaults to `1000`):\\\\n\\\\t\\\\tSize of the buffer.\\\\n\\\\t\\\\t\\\\nReturns:\\\\n\\\\t`IterableDatasetDict`: A copy of the dataset dictionary with the same datasets with shuffled rows."}\n"""',
    },
    {
        "role": "user",
        "content": "Input code:\n```\nimport warnings\nfrom math import ceil\nfrom typing import Iterable, List, Optional, Tuple, Union\n\nimport numpy as np\n\nfrom .image_utils import (\n    ImageInput,\n    get_channel_dimension_axis,\n    get_image_size,\n    infer_channel_dimension_format,\n)\nimport torch\n\nclass ChannelDimension(ExplicitEnum):\n    FIRST = \"channels_first\"\n    LAST = \"channels_last\"\n\ndef to_channel_dimension_format(\n    image: np.ndarray,\n    channel_dim: Union[ChannelDimension, str],\n    input_channel_dim: Optional[Union[ChannelDimension, str]] = None,\n) -> np.ndarray:\n    if not isinstance(image, np.ndarray):\n        raise TypeError(f\"Input image must be of type np.ndarray, got {type(image)}\")\n\n    if input_channel_dim is None:\n        input_channel_dim = infer_channel_dimension_format(image)\n\n    target_channel_dim = ChannelDimension(channel_dim)\n    if input_channel_dim == target_channel_dim:\n        return image\n\n    if target_channel_dim == ChannelDimension.FIRST:\n        image = image.transpose((2, 0, 1))\n    elif target_channel_dim == ChannelDimension.LAST:\n        image = image.transpose((1, 2, 0))\n    else:\n        raise ValueError(\"Unsupported channel dimension format: {}\".format(channel_dim))\n\n    return image\n\n\ndef rescale(\n    image: np.ndarray,\n    scale: float,\n    data_format: Optional[ChannelDimension] = None,\n    dtype: np.dtype = np.float32,\n    input_data_format: Optional[Union[str, ChannelDimension]] = None,\n) -> np.ndarray:\n    if not isinstance(image, np.ndarray):\n        raise TypeError(f\"Input image must be of type np.ndarray, got {type(image)}\")\n\n    rescaled_image = image.astype(np.float64) * scale  # Numpy type promotion has changed, so always upcast first\n    if data_format is not None:\n        rescaled_image = to_channel_dimension_format(rescaled_image, data_format, input_data_format)\n\n    rescaled_image = rescaled_image.astype(dtype)  # Finally downcast to the desired dtype at the end\n\n    return rescaled_image\n\n\ndef _rescale_for_pil_conversion(image):\n    if image.dtype == np.uint8:\n        do_rescale = False\n    elif np.allclose(image, image.astype(int)):\n        if np.all(0 <= image) and np.all(image <= 255):\n            do_rescale = False\n        else:\n            raise ValueError(\n                \"The image to be converted to a PIL image contains values outside the range [0, 255], \"\n                f\"got [{image.min()}, {image.max()}] which cannot be converted to uint8.\"\n            )\n    elif np.all(0 <= image) and np.all(image <= 1):\n        do_rescale = True\n    else:\n        raise ValueError(\n            \"The image to be converted to a PIL image contains values outside the range [0, 1], \"\n            f\"got [{image.min()}, {image.max()}] which cannot be converted to uint8.\"\n        )\n    return do_rescale\n```\n\nJson schema:\n```\n{'properties': {'class_ChannelDimension': {'description': 'Docstring for the class `ChannelDimension`', 'title': 'Class Channeldimension', 'type': 'string'}, 'function_to_channel_dimension_format': {'description': 'Docstring for the function `to_channel_dimension_format`', 'title': 'Function To Channel Dimension Format', 'type': 'string'}, 'function_rescale': {'description': 'Docstring for the function `rescale`', 'title': 'Function Rescale', 'type': 'string'}, 'function__rescale_for_pil_conversion': {'description': 'Docstring for the function `_rescale_for_pil_conversion`', 'title': 'Function  Rescale For Pil Conversion', 'type': 'string'}}, 'required': ['class_ChannelDimension', 'function_to_channel_dimension_format', 'function_rescale', 'function__rescale_for_pil_conversion'], 'title': 'DocstringModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '"""\n{"class_ChannelDimension": "", "function_to_channel_dimension_format": "Converts `image` to the channel dimension format specified by `channel_dim`.\\\\n\\\\nArgs:\\\\n\\\\timage (`numpy.ndarray`):\\\\n\\\\t\\\\tThe image to have its channel dimension set.\\\\n\\\\tchannel_dim (`ChannelDimension`):\\\\n\\\\t\\\\tThe channel dimension format to use.\\\\n\\\\tinput_channel_dim (`ChannelDimension`, *optional*):\\\\n\\\\t\\\\tThe channel dimension format of the input image. If not provided, it will be inferred from the input image.\\\\n\\\\nReturns:\\\\n\\\\t`np.ndarray`: The image with the channel dimension set to `channel_dim`.", "function_rescale": "Rescales `image` by `scale`.\\\\n\\\\nArgs:\\\\n\\\\timage (`np.ndarray`):\\\\n\\\\t\\\\tThe image to rescale.\\\\n\\\\tscale (`float`):\\\\n\\\\t\\\\tThe scale to use for rescaling the image.\\\\n\\\\tdata_format (`ChannelDimension`, *optional*):\\\\n\\\\t\\\\tThe channel dimension format of the image. If not provided, it will be the same as the input image.\\\\n\\\\tdtype (`np.dtype`, *optional*, defaults to `np.float32`):\\\\n\\\\t\\\\tThe dtype of the output image. Defaults to `np.float32`. Used for backwards compatibility with feature\\\\n\\\\t\\\\textractors.\\\\n\\\\tinput_data_format (`ChannelDimension`, *optional*):\\\\n\\\\t\\\\tThe channel dimension format of the input image. If not provided, it will be inferred from the input image.\\\\n\\\\nReturns:\\\\n\\\\t`np.ndarray`: The rescaled image.", "function__rescale_for_pil_conversion": "Detects whether or not the image needs to be rescaled before being converted to a PIL image.\\\\n\\\\nThe assumption is that if `image` is of type `np.float` and all values are between 0 and 1, it needs to be\\\\nrescaled.\\\\n\\\\nArgs:\\\\n\\\\timage (`np.ndarray`):\\\\n\\\\t\\\\tThe image, which potentially needs to be rescaled.\\\\n\\\\nReturns:\\\\n\\\\t`bool`: True if the image needs to be rescaled, else False"}\n"""',
    },
    {
        "role": "user",
        "content": "Input code:\n```\nfrom typing import Optional, Union\n\nimport torch\nfrom ..utils import add_start_docstrings, logging\nfrom .stopping_criteria import StoppingCriteria\n\nlogger = logging.get_logger(__name__)\n\ndef is_within_length_limits(current_length: int, max_length: int) -> bool:\n    return current_length < max_length and current_length >= 0\n\nclass MaxLengthCriteria(StoppingCriteria):\n\n    max_length: int\n    max_position_embeddings: Optional[int] = None\n\n    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> torch.BoolTensor:\n        cur_len = input_ids.shape[-1]\n        is_done = cur_len >= self.max_length\n        if self.max_position_embeddings is not None and not is_done and cur_len >= self.max_position_embeddings:\n            logger.warning_once(\n                \"This is a friendly reminder - the current text generation call will exceed the model's predefined \"\n                f\"maximum length ({self.max_position_embeddings}). Depending on the model, you may observe \"\n                \"exceptions, performance degradation, or nothing at all.\"\n            )\n        return torch.full((input_ids.shape[0],), is_done, device=input_ids.device, dtype=torch.bool)\n        \nclass DynamicStateHandler:\n    def __init__(self, payload: Any = None, mode: str = \"auto\", **kwargs):\n        self._internal_state = {}\n        self.payload = payload\n        self._mode = mode\n        self._temporary_flags = kwargs.get('flags', {})\n    \n    def process(self, data: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n        if self._mode == \"auto\":\n            return {**data, \"processed\": True}\n        return None\n```\n\nJson schema:\n```\n{'properties': {'function_is_within_length_limits': {'description': 'Docstring for the function `is_within_length_limits`', 'title': 'Function Is Within Length Limits', 'type': 'string'}, 'class_MaxLengthCriteria': {'description': 'Docstring for the class `MaxLengthCriteria`', 'title': 'Class Maxlengthcriteria', 'type': 'string'}, 'class_MaxLengthCriteria_method___init__': {'description': 'Docstring for the method `__init__` of the class `MaxLengthCriteria`', 'title': 'Class Maxlengthcriteria Method   Init  ', 'type': 'string'}, 'class_MaxLengthCriteria_method___call__': {'description': 'Docstring for the method `__call__` of the class `MaxLengthCriteria`', 'title': 'Class Maxlengthcriteria Method   Call  ', 'type': 'string'}, 'class_DynamicStateHandler': {'description': 'Docstring for the class `DynamicStateHandler`', 'title': 'Class Dynamicstatehandler', 'type': 'string'}, 'class_DynamicStateHandler_method___init__': {'description': 'Docstring for the method `__init__` of the class `DynamicStateHandler`', 'title': 'Class Dynamicstatehandler Method   Init  ', 'type': 'string'}, 'class_DynamicStateHandler_method_process': {'description': 'Docstring for the method `process` of the class `DynamicStateHandler`', 'title': 'Class Dynamicstatehandler Method Process', 'type': 'string'}}, 'required': ['function_is_within_length_limits', 'class_MaxLengthCriteria', 'class_MaxLengthCriteria_method___init__', 'class_MaxLengthCriteria_method___call__', 'class_DynamicStateHandler', 'class_DynamicStateHandler_method___init__', 'class_DynamicStateHandler_method_process'], 'title': 'DocstringModel', 'type': 'object'}\n```",
    },
    {
        "role": "assistant",
        "content": '"""\n{"function_is_within_length_limits": "", "class_MaxLengthCriteria": "This class can be used to stop generation whenever the full generated number of tokens exceeds `max_length`. Keep\\\\nin mind for decoder-only type of transformers, this will include the initial prompted tokens.\\\\n\\\\nArgs:\\\\n\\\\tmax_length (`int`):\\\\n\\\\t\\\\tThe maximum length that the output sequence can have in number of tokens.\\\\n\\\\tmax_position_embeddings (`int`, *optional*):\\\\n\\\\t\\\\tThe maximum model length, as defined by the model\'s `config.max_position_embeddings` attribute.", "class_MaxLengthCriteria_method___init__": "", "class_MaxLengthCriteria_method___call__": "Args:\\\\n\\\\t\\\\tinput_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\\\\n\\\\t\\\\t\\\\tIndices of input sequence tokens in the vocabulary.\\\\n\\\\t\\\\tscores (`torch.FloatTensor` of shape `(batch_size, config.vocab_size)`):\\\\n\\\\t\\\\t\\\\tPrediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax\\\\n\\\\t\\\\t\\\\tor scores for each vocabulary token after SoftMax. If this stopping criteria depends on the `scores` input,\\\\n\\\\t\\\\t\\\\tmake sure you pass `return_dict_in_generate=True, output_scores=True` to `generate`.\\\\n\\\\t\\\\tkwargs (`Dict[str, Any]`, *optional*):\\\\n\\\\t\\\\t\\\\tAdditional stopping criteria specific kwargs.\\\\n\\\\n\\\\tReturn:\\\\n\\\\t\\\\t`torch.BoolTensor`. (`torch.BoolTensor` of shape `(batch_size, 1)`), where `True` indicates we stop generation\\\\n\\\\t\\\\t\\\\tfor a particular row, `True` indicates we should continue.", "class_DynamicStateHandler": "", "class_DynamicStateHandler_method___init__": "", "class_DynamicStateHandler_method_process": ""}\n"""',
    },
]

MESSAGES_COMMENTS = [
    {
        "role": "system",
        "content": "Act as an experienced Python specialist.\n\nWrite comment strings (or multistrings) for the code where necessary following the provided json schema. Write comments if and only if you are confident that your comment is (1) correct and (2) required for better understanding of the code. If the line is easy to understand or doesn't require a comment, leave the comment empty. If there is a chance that your comment may be incorrect or is a hallucination, leave it empty as well. It is much more dangerous to write an incorrect comment than to leave it empty. Don't write comments to every single line - only write it if a comment will mitigate understanding of the code AND you are sure your comment is correct.",
    },
    {
        "role": "user",
        "content": 'Input code:\n```\nimport numpy as np\n\n\nclass PortfolioAnalyzer:\n    """\n    A class for analyzing a portfolio of stocks. It provides methods to calculate volatility, Sharpe ratio, and optimize portfolio weights based on mean-variance optimization.\n    """\n\n    def __init__(self, portfolio_data: dict[str, list[float]]):\n        """\n        Initialize the PortfolioAnalyzer with portfolio data.\n\n        Args:\n            portfolio_data (`dict[str, list[float]]`):\n                A dictionary with stock symbols as keys and lists of historical prices as values.\n        """\n        self.portfolio = portfolio_data\n        self.metrics = {}\n\n    def calculate_volatility(self, symbol: str) -> float:\n        """\n        Calculate the annualized volatility for a given stock.\n\n        Args:\n            symbol (`str`):\n                The stock symbol for which to calculate the volatility.\n\n        Returns:\n            `float`: The annualized volatility of the stock.\n        """\n        prices = np.array(self.portfolio[symbol])\n        returns = np.diff(prices) / prices[:-1]\n\n        annual_volatility = np.std(returns) * np.sqrt(252)\n        return annual_volatility\n\n    def sharpe_ratio(self, symbol: str, risk_free_rate: float = 0.02) -> float:\n        """\n        Calculate the Sharpe ratio for a given stock.\n\n        Args:\n            symbol (`str`):\n                The stock symbol for which to calculate the Sharpe ratio.\n            risk_free_rate (`float`, *optional*, defaults to `0.02`):\n                The risk-free rate to use in the Sharpe ratio calculation.\n\n        Returns:\n            `float`: The Sharpe ratio of the stock.\n        """\n        prices = self.portfolio[symbol]\n        # Calculate Sharpe ratio using the formulae\n        total_return = (prices[-1] - prices[0]) / prices[0]\n\n        annual_return = total_return * (252 / len(prices))\n        volatility = self.calculate_volatility(symbol)\n\n        return (annual_return - risk_free_rate) / volatility\n\n    def optimize_weights(self, target_return: float = 0.15) -> np.ndarray:\n        """\n        Use mean-variance optimization to find optimal portfolio weights.\n\n        Args:\n            target_return (`float`, *optional*, defaults to `0.15`):\n                The target return for the portfolio.\n\n        Returns:\n            `np.ndarray`: The covariance matrix of the returns, which is a step in the optimization process.\n\n        Note:\n            This method currently returns the covariance matrix instead of the optimal weights. This behavior should be corrected to return the optimal weights.\n        """\n        ## find optimal portfolio weights\n        returns_matrix = []\n        for symbol in self.portfolio:\n            prices = np.array(self.portfolio[symbol])\n            returns = np.diff(prices) / prices[:-1]\n            returns_matrix.append(returns)\n\n        cov_matrix = np.cov(returns_matrix)\n\n        #  for later use\n        self.metrics[\'covariance_matrix\'] = cov_matrix\n        self.metrics[\'mean_returns\'] = np.mean(returns_matrix, axis=1)\n\n        return cov_matrix\n```\n\nJson schema:\n```\n{"line1": {"description": "Comment for line 1: import numpy as np"}, "line2": {"description": "Comment for line 2: class PortfolioAnalyzer:"}, "line3": {"description": "Comment for line 3:     def __init__(self, portfolio_data: dict[str, list[float]]):"}, "line4": {"description": "Comment for line 4:         self.portfolio = portfolio_data"}, "line5": {"description": "Comment for line 5:         self.metrics = {}"}, "line6": {"description": "Comment for line 6:     def calculate_volatility(self, symbol: str) -> float:"}, "line7": {"description": "Comment for line 7:         prices = np.array(self.portfolio[symbol])"}, "line8": {"description": "Comment for line 8:         returns = np.diff(prices) / prices[:-1]"}, "line9": {"description": "Comment for line 9:         annual_volatility = np.std(returns) * np.sqrt(252)"}, "line10": {"description": "Comment for line 10:         return annual_volatility"}, "line11": {"description": "Comment for line 11:     def sharpe_ratio(self, symbol: str, risk_free_rate: float = 0.02) -> float:"}, "line12": {"description": "Comment for line 12:         prices = self.portfolio[symbol]"}, "line13": {"default": "Calculate Sharpe ratio using the formulae", "description": "Comment for line 13:         total_return = (prices[-1] - prices[0]) / prices[0]"}, "line14": {"description": "Comment for line 14:         annual_return = total_return * (252 / len(prices))"}, "line15": {"description": "Comment for line 15:         volatility = self.calculate_volatility(symbol)"}, "line16": {"description": "Comment for line 16:         return (annual_return - risk_free_rate) / volatility"}, "line17": {"description": "Comment for line 17:     def optimize_weights(self, target_return: float = 0.15) -> np.ndarray:"}, "line18": {"default": "# find optimal portfolio weights", "description": "Comment for line 18:         returns_matrix = []"}, "line19": {"description": "Comment for line 19:         for symbol in self.portfolio:"}, "line20": {"description": "Comment for line 20:             prices = np.array(self.portfolio[symbol])"}, "line21": {"description": "Comment for line 21:             returns = np.diff(prices) / prices[:-1]"}, "line22": {"description": "Comment for line 22:             returns_matrix.append(returns)"}, "line23": {"description": "Comment for line 23:         cov_matrix = np.cov(returns_matrix)"}, "line24": {"default": "for later use", "description": "Comment for line 24:         self.metrics[\'covariance_matrix\'] = cov_matrix"}, "line25": {"description": "Comment for line 25:         self.metrics[\'mean_returns\'] = np.mean(returns_matrix, axis=1)"}, "line26": {"description": "Comment for line 26:         return cov_matrix"}}\n```',
    },
    {
        "role": "assistant",
        "content": '{"line1": "", "line2": "", "line3": "", "line4": "", "line5": "", "line6": "", "line7": "", "line8": "Calculate daily returns", "line9": "Annualize the volatility by multiplying by the square root of the number of trading days (252)", "line10": "", "line11": "", "line12": "", "line13": "## Calculate the Sharpe ratio: (annual_return - risk_free_rate) / volatility\\nCalculate the total return over the period", "line14": "Annualize the return (assuming one year of data)", "line15": "Get the annualized volatility for the stock", "line16": "Get the Sharpe ratio", "line17": "", "line18": "Create a matrix to store the returns of each stock", "line19": "Calculate the percentage returns from the prices for each stock in the portfolio", "line20": "", "line21": "", "line22": "", "line23": "Calculate the covariance matrix of the returns", "line24": "Store the results in the metrics dictionary", "line25": "", "line26": ""}',
    },
    {
        "role": "user",
        "content": 'Input code:\n```\ndef create_pydantic_model_class(name: str) -> dict[str, tuple[Any, Field]]:\n\t"""\n\tCreates a dictionary entry for a Pydantic model field representing a class docstring.\n\n\tArgs:\n\t\tname (`str`):\n\t\t\tThe name of the class.\n\n\tReturns:\n\t\t`dict[str, tuple[Any, Field]]`: A dictionary with a single key-value pair where the key is the formatted class name and the value is a tuple containing the type `str` and a `Field` object with a description.\n\t"""\n\n\treturn {\n\t\t"class_"\n\t\t+ name: (str, Field(..., description=f"Docstring for the class `{name}`"))\n\t}\ndef create_pydantic_model_function(name: str) -> dict[str, tuple[Any, Field]]:\n\t"""\n\tCreates a dictionary entry for a Pydantic model field representing a function docstring.\n\n\tArgs:\n\t\tname (`str`):\n\t\t\tThe name of the function.\n\n\tReturns:\n\t\t`dict[str, tuple[Any, Field]]`: A dictionary with a single key-value pair where the key is the formatted function name and the value is a tuple containing the type `str` and a `Field` object with a description.\n\t"""\n\n\treturn {\n\t\t"function_"\n\t\t+ name: (str, Field(..., description=f"Docstring for the function `{name}`"))\n\t}\ndef get_system_prompt(use_long_system_prompt: bool = True) -> str:\n\t"""\n\tReturns a system prompt string, optionally extended with additional content.\n\n\tArgs:\n\t\tuse_long_system_prompt (`bool`, *optional*, defaults to `True`):\n\t\t\tIf `True`, the returned prompt includes additional content.\n\n\tReturns:\n\t\t`str`: The system prompt string, possibly extended with additional content.\n\t"""\n\n\tif use_long_system_prompt:\n\t\treturn SYSTEM_PROMPT_DOCSTRING + SYSTEM_PROMPT_DOCSTRING_ADDITION\n\treturn SYSTEM_PROMPT_DOCSTRING\n```\n\nJson schema:\n```\n{"line1": {"description": "Comment for line 1: def create_pydantic_model_class(name: str) -> dict[str, tuple[Any, Field]]:"}, "line2": {"description": "Comment for line 2: \\treturn {"}, "line3": {"description": "Comment for line 3: \\t\\t\\"class_\\""}, "line4": {"description": "Comment for line 4: \\t\\t+ name: (str, Field(..., description=f\\"Docstring for the class `{name}`\\"))"}, "line5": {"description": "Comment for line 5: \\t}"}, "line6": {"description": "Comment for line 6: def create_pydantic_model_function(name: str) -> dict[str, tuple[Any, Field]]:"}, "line7": {"description": "Comment for line 7: \\treturn {"}, "line8": {"description": "Comment for line 8: \\t\\t\\"function_\\""}, "line9": {"description": "Comment for line 9: \\t\\t+ name: (str, Field(..., description=f\\"Docstring for the function `{name}`\\"))"}, "line10": {"description": "Comment for line 10: \\t}"}, "line11": {"description": "Comment for line 11: def get_system_prompt(use_long_system_prompt: bool = True) -> str:"}, "line12": {"description": "Comment for line 12: \\tif use_long_system_prompt:"}, "line13": {"description": "Comment for line 13: \\t\\treturn SYSTEM_PROMPT_DOCSTRING + SYSTEM_PROMPT_DOCSTRING_ADDITION"}, "line14": {"description": "Comment for line 14: \\treturn SYSTEM_PROMPT_DOCSTRING"}}\n```',
    },
    {
        "role": "assistant",
        "content": '{"line1": "", "line2": "", "line3": "", "line4": "", "line5": "", "line6": "", "line7": "", "line8": "", "line9": "", "line10": "", "line11": "", "line12": "", "line13": "", "line14": ""}',
    },
    {
        "role": "user",
        "content": 'Input code:\n```\ndef get_docstring_position_in_code(\n\tnode: Union[ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef],\n\tcode: str,\n\tlines_shift: int,\n) -> Union[tuple[int, int], None]:\n\t"""\n\tDetermines the start and end positions of a docstring within the source code of a function, async function, or class. If no docstring exists, it returns the position where a docstring should be inserted.\n\n\tArgs:\n\t\tnode (`Union[ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef]`):\n\t\t\tThe AST node representing the function, async function, or class.\n\t\tcode (`str`):\n\t\t\tThe source code as a string.\n\t\tlines_shift (`int`):\n\t\t\tAn integer shift to adjust line numbers (useful if the code snippet is part of a larger file).\n\n\tReturns:\n\t\t`Union[tuple[int, int], None]`: A tuple containing the start and end positions of the docstring in the source code, or `None` if the input node is not a function, async function, or class.\n\t"""\n\n\tif not isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n\t\treturn None\n\n\tif (\n\t\tnode.body\n\t\tand isinstance(node.body[0], ast.Expr)\n\t\tand isinstance(node.body[0].value, (ast.Str, ast.Constant))\n\t):\n\t\tdoc_node = node.body[0]\n\t\tlines = code.splitlines()\n\n\t\tstart = sum(\n\t\t\tlen(line) + 1 for line in lines[: doc_node.lineno - 1 + lines_shift]\n\t\t)\n\t\tstart += doc_node.col_offset\n\n        # in this case docstring is single-line\n\t\tif doc_node.lineno == doc_node.end_lineno:\n\t\t\tline = lines[doc_node.lineno - 1 + lines_shift]\n\t\t\tquote_type = line[doc_node.col_offset : doc_node.col_offset + 3]\n\t\t\tif quote_type in (\'"""\', "\'\'\'"):\n\t\t\t\tend = line.find(quote_type, doc_node.col_offset + 3) + 3\n\t\t\telse:\n\t\t\t\tquote_type = line[doc_node.col_offset]\n\t\t\t\tend = line.find(quote_type, doc_node.col_offset + 1) + 1\n\t\t\tend = start + (end - doc_node.col_offset)\n\t\telse:\n\t\t\tlast_line = lines[doc_node.end_lineno - 1 + lines_shift].rstrip()\n\t\t\tend = sum(\n\t\t\t\tlen(line) + 1 for line in lines[: doc_node.end_lineno - 1 + lines_shift]\n\t\t\t)\n\t\t\tend += len(last_line)\n\n\t\treturn start, end\n\n\tpos = _get_docstring_position_with_no_docstring(node=node, code=code, lines_shift=lines_shift)\n\t# return twice to match the format\n\treturn pos, pos\n```\n\nJson schema:\n```\n{"line1": {"description": "Comment for line 1: def get_docstring_position_in_code("}, "line2": {"description": "Comment for line 2: \\tnode: Union[ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef],"}, "line3": {"description": "Comment for line 3: \\tcode: str,"}, "line4": {"description": "Comment for line 4: \\tlines_shift: int,"}, "line5": {"description": "Comment for line 5: ) -> Union[tuple[int, int], None]:"}, "line6": {"description": "Comment for line 6: \\tif not isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):"}, "line7": {"description": "Comment for line 7: \\t\\treturn None"}, "line8": {"description": "Comment for line 8: \\tif ("}, "line9": {"description": "Comment for line 9: \\t\\tnode.body"}, "line10": {"description": "Comment for line 10: \\t\\tand isinstance(node.body[0], ast.Expr)"}, "line11": {"description": "Comment for line 11: \\t\\tand isinstance(node.body[0].value, (ast.Str, ast.Constant))"}, "line12": {"description": "Comment for line 12: \\t):"}, "line13": {"description": "Comment for line 13: \\t\\tdoc_node = node.body[0]"}, "line14": {"description": "Comment for line 14: \\t\\tlines = code.splitlines()"}, "line15": {"description": "Comment for line 15: \\t\\tstart = sum("}, "line16": {"description": "Comment for line 16: \\t\\t\\tlen(line) + 1 for line in lines[: doc_node.lineno - 1 + lines_shift]"}, "line17": {"description": "Comment for line 17: \\t\\t)"}, "line18": {"description": "Comment for line 18: \\t\\tstart += doc_node.col_offset"}, "line19": {"default": "in this case docstring is single-line", "description": "Comment for line 19: \\t\\tif doc_node.lineno == doc_node.end_lineno:"}, "line20": {"description": "Comment for line 20: \\t\\t\\tline = lines[doc_node.lineno - 1 + lines_shift]"}, "line21": {"description": "Comment for line 21: \\t\\t\\tquote_type = line[doc_node.col_offset : doc_node.col_offset + 3]"}, "line22": {"description": "Comment for line 22: \\t\\t\\tif quote_type in (\'\\"\\"\\"\', \\"\'\'\'\\"):"}, "line23": {"description": "Comment for line 23: \\t\\t\\t\\tend = line.find(quote_type, doc_node.col_offset + 3) + 3"}, "line24": {"description": "Comment for line 24: \\t\\t\\telse:"}, "line25": {"description": "Comment for line 25: \\t\\t\\t\\tquote_type = line[doc_node.col_offset]"}, "line26": {"description": "Comment for line 26: \\t\\t\\t\\tend = line.find(quote_type, doc_node.col_offset + 1) + 1"}, "line27": {"description": "Comment for line 27: \\t\\t\\tend = start + (end - doc_node.col_offset)"}, "line28": {"description": "Comment for line 28: \\t\\telse:"}, "line29": {"description": "Comment for line 29: \\t\\t\\tlast_line = lines[doc_node.end_lineno - 1 + lines_shift].rstrip()"}, "line30": {"description": "Comment for line 30: \\t\\t\\tend = sum("}, "line31": {"description": "Comment for line 31: \\t\\t\\t\\tlen(line) + 1 for line in lines[: doc_node.end_lineno - 1 + lines_shift]"}, "line32": {"description": "Comment for line 32: \\t\\t\\t)"}, "line33": {"description": "Comment for line 33: \\t\\t\\tend += len(last_line)"}, "line34": {"description": "Comment for line 34: \\t\\treturn start, end"}, "line35": {"description": "Comment for line 35: \\tpos = _get_docstring_position_with_no_docstring(node=node, code=code, lines_shift=lines_shift)"}, "line36": {"default": "return twice to match the format", "description": "Comment for line 36: \\treturn pos, pos"}}\n```',
    },
    {
        "role": "assistant",
        "content": '{"line1": "", "line2": "", "line3": "", "line4": "", "line5": "", "line6": "", "line7": "", "line8": "Check if the docstring already exists", "line9": "", "line10": "", "line11": "", "line12": "", "line13": "Get the AST node of the docstring", "line14": "", "line15": "Calculate docstring\'s start position by:\\n1. Summing lengths of all previous lines (including newline chars)\\n2. Adding the column offset of the current line (number of preceding chars in the current line)", "line16": "", "line17": "", "line18": "", "line19": "Check if the docstring is single-line by comparing\\nits start and end line numbers", "line20": "Get the line containing the docstring", "line21": "Determine the type of the quote used for the docstring", "line22": "Check if the docstring is enclosed in triple quotes", "line23": "Find the position of the closing triple quote", "line24": "Handle single quotes", "line25": "Determine the type of the quote used for the docstring", "line26": "Find the position of the closing single quote", "line27": "Calculate the end position of the docstring", "line28": "Handle multi-line docstrings", "line29": "Get the last line of the docstring", "line30": "Calculate the starting position of the last line of the docstring", "line31": "", "line32": "", "line33": "Add the length of the last line to the end position", "line34": "Return the start and end positions of the docstring", "line35": "Get the position where a docstring should be inserted if it doesn\'t exist", "line36": "Return the position twice since the start and end positions are the same"}',
    },
    {
        "role": "user",
        "content": 'Input code:\n```\nfrom typing import Union, Optional, Any\n\nclass DynamicStateHandler:\n    def __init__(self, payload: Any = None, mode: str = "auto", **kwargs):\n        self._internal_state = {}\n        self.payload = payload\n        self._mode = mode\n        self._temporary_flags = kwargs.get(\'flags\', {})\n\n    def process(self, data: dict[str, Any]) -> Optional[dict[str, Any]]:\n        if self._mode == "auto":\n            return {**data, "processed": True}\n        return None\n```\n\nJson schema:\n```\n{"line1": {"description": "Comment for line 1: from typing import Union, Optional, Any"}, "line2": {"description": "Comment for line 2: class DynamicStateHandler:"}, "line3": {"description": "Comment for line 3:     def __init__(self, payload: Any = None, mode: str = \\"auto\\", **kwargs):"}, "line4": {"description": "Comment for line 4:         self._internal_state = {}"}, "line5": {"description": "Comment for line 5:         self.payload = payload"}, "line6": {"description": "Comment for line 6:         self._mode = mode"}, "line7": {"description": "Comment for line 7:         self._temporary_flags = kwargs.get(\'flags\', {})"}, "line8": {"description": "Comment for line 8:     def process(self, data: dict[str, Any]) -> Optional[dict[str, Any]]:"}, "line9": {"description": "Comment for line 9:         if self._mode == \\"auto\\":"}, "line10": {"description": "Comment for line 10:             return {**data, \\"processed\\": True}"}, "line11": {"description": "Comment for line 11:         return None"}}\n```',
    },
    {
        "role": "assistant",
        "content": '{"line1": "", "line2": "", "line3": "", "line4": "", "line5": "", "line6": "", "line7": "", "line8": "", "line9": "", "line10": "", "line11": ""}',
    },
    {
        "role": "user",
        "content": 'Input code:\n```\nimport math\nfrom typing import List, Optional, Tuple, Union\nimport torch\nfrom pos_embed import _get_3d_sincos_pos_embed_np, get_2d_sincos_pos_embed_from_grid, get_1d_sincos_pos_embed_from_grid\n\n\ndef get_timestep_embedding(\n\ttimesteps: torch.Tensor,\n\tembedding_dim: int,\n\tflip_sin_to_cos: bool = False,\n\tdownscale_freq_shift: float = 1,\n\tscale: float = 1,\n\tmax_period: int = 10000,\n) -> torch.Tensor:\n\t"""\n\tCreates sinusoidal timestep embeddings, matching the implementation in Denoising Diffusion Probabilistic Models.\n\t\n\tArgs:\n\t\ttimesteps (`torch.Tensor`):\n\t\t\tA 1-D Tensor of N indices, one per batch element. These may be fractional.\n\t\tembedding_dim (`int`):\n\t\t\tThe dimension of the output embeddings.\n\t\tflip_sin_to_cos (`bool`, defaults to `False`):\n\t\t\tWhether the embedding order should be `cos, sin` (if True) or `sin, cos` (if False).\n\t\tdownscale_freq_shift (`float`, defaults to `1`):\n\t\t\tControls the delta between frequencies between dimensions.\n\t\tscale (`float`, defaults to `1`):\n\t\t\tScaling factor applied to the embeddings.\n\t\tmax_period (`int`, defaults to `10000`):\n\t\t\tControls the maximum frequency of the embeddings.\n\t\n\tReturns:\n\t\t`torch.Tensor`: An [N x dim] Tensor of positional embeddings.\n\t"""\n\tassert len(timesteps.shape) == 1, "Timesteps should be a 1d-array"\n\n    half_dim = embedding_dim // 2\n    exponent = -math.log(max_period) * torch.arange(\n        start=0, end=half_dim, dtype=torch.float32, device=timesteps.device\n    )\n    exponent = exponent / (half_dim - downscale_freq_shift)\n\n    emb = torch.exp(exponent)\n    emb = timesteps[:, None].float() * emb[None, :]\n\n    emb = scale * emb\n\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n\n    if flip_sin_to_cos:\n        emb = torch.cat([emb[:, half_dim:], emb[:, :half_dim]], dim=-1)\n\n    if embedding_dim % 2 == 1:\n        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n    return emb\n\ndef get_3d_sincos_pos_embed(\n\tembed_dim: int,\n\tspatial_size: Union[int, Tuple[int, int]],\n\ttemporal_size: int,\n\tspatial_interpolation_scale: float = 1.0,\n\ttemporal_interpolation_scale: float = 1.0,\n\tdevice: Optional[torch.device] = None,\n\toutput_type: str = "np",\n) -> torch.Tensor:\n\t"""\n\tCreates 3D sinusoidal positional embeddings.\n\t\n\tArgs:\n\t\tembed_dim (`int`):\n\t\t\tThe embedding dimension of inputs. It must be divisible by 4.\n\t\tspatial_size (`int` or `Tuple[int, int]`):\n\t\t\tThe spatial dimension of positional embeddings. If an integer is provided, the same size is applied to both\n\t\t\tspatial dimensions (height and width).\n\t\ttemporal_size (`int`):\n\t\t\tThe temporal dimension of positional embeddings (number of frames).\n\t\tspatial_interpolation_scale (`float`, defaults to `1.0`):\n\t\t\tScale factor for spatial grid interpolation.\n\t\ttemporal_interpolation_scale (`float`, defaults to `1.0`):\n\t\t\tScale factor for temporal grid interpolation.\n\t\tdevice (`torch.device`, *optional*):\n\t\t\tDevice to place the embeddings on.\n\t\toutput_type (`str`, defaults to `\'np\'`):\n\t\t\tType of the output embeddings. Can be `\'np\'` for NumPy arrays or `\'pt\'` for PyTorch tensors.\n\t\n\tReturns:\n\t\t`torch.Tensor`: The 3D sinusoidal positional embeddings of shape `[temporal_size, spatial_size[0] * spatial_size[1], embed_dim]`.\n\t"""\n\tif output_type == "np":\n        return _get_3d_sincos_pos_embed_np(\n            embed_dim=embed_dim,\n            spatial_size=spatial_size,\n            temporal_size=temporal_size,\n            spatial_interpolation_scale=spatial_interpolation_scale,\n            temporal_interpolation_scale=temporal_interpolation_scale,\n        )\n    if embed_dim % 4 != 0:\n        raise ValueError("`embed_dim` must be divisible by 4")\n    if isinstance(spatial_size, int):\n        spatial_size = (spatial_size, spatial_size)\n\n    embed_dim_spatial = 3 * embed_dim // 4\n    embed_dim_temporal = embed_dim // 4\n\n    # spatoal\n    grid_h = torch.arange(spatial_size[1], device=device, dtype=torch.float32) / spatial_interpolation_scale\n    grid_w = torch.arange(spatial_size[0], device=device, dtype=torch.float32) / spatial_interpolation_scale\n    grid = torch.meshgrid(grid_w, grid_h, indexing="xy")  # here w goes first\n    grid = torch.stack(grid, dim=0)\n\n    grid = grid.reshape([2, 1, spatial_size[1], spatial_size[0]])\n    pos_embed_spatial = get_2d_sincos_pos_embed_from_grid(embed_dim_spatial, grid, output_type="pt")\n\n    # temporal\n    grid_t = torch.arange(temporal_size, device=device, dtype=torch.float32) / temporal_interpolation_scale\n    pos_embed_temporal = get_1d_sincos_pos_embed_from_grid(embed_dim_temporal, grid_t, output_type="pt")\n\n    # concat\n    pos_embed_spatial = pos_embed_spatial[None, :, :]\n    pos_embed_spatial = pos_embed_spatial.repeat_interleave(temporal_size, dim=0)  # [T, H*W, D // 4 * 3]\n\n    pos_embed_temporal = pos_embed_temporal[:, None, :]\n    pos_embed_temporal = pos_embed_temporal.repeat_interleave(\n        spatial_size[0] * spatial_size[1], dim=1\n    )\n\n    pos_embed = torch.concat([pos_embed_temporal, pos_embed_spatial], dim=-1)\n    return pos_embed\n```\n\nJson schema:\n```\n{"line1": {"description": "Comment for line 1: import math"}, "line2": {"description": "Comment for line 2: from typing import List, Optional, Tuple, Union"}, "line3": {"description": "Comment for line 3: import torch"}, "line4": {"description": "Comment for line 4: from pos_embed import _get_3d_sincos_pos_embed_np, get_2d_sincos_pos_embed_from_grid, get_1d_sincos_pos_embed_from_grid"}, "line5": {"description": "Comment for line 5: def get_timestep_embedding("}, "line6": {"description": "Comment for line 6: \\ttimesteps: torch.Tensor,"}, "line7": {"description": "Comment for line 7: \\tembedding_dim: int,"}, "line8": {"description": "Comment for line 8: \\tflip_sin_to_cos: bool = False,"}, "line9": {"description": "Comment for line 9: \\tdownscale_freq_shift: float = 1,"}, "line10": {"description": "Comment for line 10: \\tscale: float = 1,"}, "line11": {"description": "Comment for line 11: \\tmax_period: int = 10000,"}, "line12": {"description": "Comment for line 12: ) -> torch.Tensor:"}, "line13": {"description": "Comment for line 13: \\tassert len(timesteps.shape) == 1, \\"Timesteps should be a 1d-array\\""}, "line14": {"description": "Comment for line 14:     half_dim = embedding_dim // 2"}, "line15": {"description": "Comment for line 15:     exponent = -math.log(max_period) * torch.arange("}, "line16": {"description": "Comment for line 16:         start=0, end=half_dim, dtype=torch.float32, device=timesteps.device"}, "line17": {"description": "Comment for line 17:     )"}, "line18": {"description": "Comment for line 18:     exponent = exponent / (half_dim - downscale_freq_shift)"}, "line19": {"description": "Comment for line 19:     emb = torch.exp(exponent)"}, "line20": {"description": "Comment for line 20:     emb = timesteps[:, None].float() * emb[None, :]"}, "line21": {"description": "Comment for line 21:     emb = scale * emb"}, "line22": {"description": "Comment for line 22:     emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)"}, "line23": {"description": "Comment for line 23:     if flip_sin_to_cos:"}, "line24": {"description": "Comment for line 24:         emb = torch.cat([emb[:, half_dim:], emb[:, :half_dim]], dim=-1)"}, "line25": {"description": "Comment for line 25:     if embedding_dim % 2 == 1:"}, "line26": {"description": "Comment for line 26:         emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))"}, "line27": {"description": "Comment for line 27:     return emb"}, "line28": {"description": "Comment for line 28: def get_3d_sincos_pos_embed("}, "line29": {"description": "Comment for line 29: \\tembed_dim: int,"}, "line30": {"description": "Comment for line 30: \\tspatial_size: Union[int, Tuple[int, int]],"}, "line31": {"description": "Comment for line 31: \\ttemporal_size: int,"}, "line32": {"description": "Comment for line 32: \\tspatial_interpolation_scale: float = 1.0,"}, "line33": {"description": "Comment for line 33: \\ttemporal_interpolation_scale: float = 1.0,"}, "line34": {"description": "Comment for line 34: \\tdevice: Optional[torch.device] = None,"}, "line35": {"description": "Comment for line 35: \\toutput_type: str = \\"np\\","}, "line36": {"description": "Comment for line 36: ) -> torch.Tensor:"}, "line37": {"description": "Comment for line 37: \\tif output_type == \\"np\\":"}, "line38": {"description": "Comment for line 38:         return _get_3d_sincos_pos_embed_np("}, "line39": {"description": "Comment for line 39:             embed_dim=embed_dim,"}, "line40": {"description": "Comment for line 40:             spatial_size=spatial_size,"}, "line41": {"description": "Comment for line 41:             temporal_size=temporal_size,"}, "line42": {"description": "Comment for line 42:             spatial_interpolation_scale=spatial_interpolation_scale,"}, "line43": {"description": "Comment for line 43:             temporal_interpolation_scale=temporal_interpolation_scale,"}, "line44": {"description": "Comment for line 44:         )"}, "line45": {"description": "Comment for line 45:     if embed_dim % 4 != 0:"}, "line46": {"description": "Comment for line 46:         raise ValueError(\\"`embed_dim` must be divisible by 4\\")"}, "line47": {"description": "Comment for line 47:     if isinstance(spatial_size, int):"}, "line48": {"description": "Comment for line 48:         spatial_size = (spatial_size, spatial_size)"}, "line49": {"description": "Comment for line 49:     embed_dim_spatial = 3 * embed_dim // 4"}, "line50": {"description": "Comment for line 50:     embed_dim_temporal = embed_dim // 4"}, "line51": {"default": "spatoal", "description": "Comment for line 51:     grid_h = torch.arange(spatial_size[1], device=device, dtype=torch.float32) / spatial_interpolation_scale"}, "line52": {"description": "Comment for line 52:     grid_w = torch.arange(spatial_size[0], device=device, dtype=torch.float32) / spatial_interpolation_scale"}, "line53": {"default": "here w goes first", "description": "Comment for line 53:     grid = torch.meshgrid(grid_w, grid_h, indexing=\\"xy\\")"}, "line54": {"description": "Comment for line 54:     grid = torch.stack(grid, dim=0)"}, "line55": {"description": "Comment for line 55:     grid = grid.reshape([2, 1, spatial_size[1], spatial_size[0]])"}, "line56": {"description": "Comment for line 56:     pos_embed_spatial = get_2d_sincos_pos_embed_from_grid(embed_dim_spatial, grid, output_type=\\"pt\\")"}, "line57": {"default": "temporal", "description": "Comment for line 57:     grid_t = torch.arange(temporal_size, device=device, dtype=torch.float32) / temporal_interpolation_scale"}, "line58": {"description": "Comment for line 58:     pos_embed_temporal = get_1d_sincos_pos_embed_from_grid(embed_dim_temporal, grid_t, output_type=\\"pt\\")"}, "line59": {"default": "concat", "description": "Comment for line 59:     pos_embed_spatial = pos_embed_spatial[None, :, :]"}, "line60": {"default": "[T, H*W, D // 4 * 3]", "description": "Comment for line 60:     pos_embed_spatial = pos_embed_spatial.repeat_interleave(temporal_size, dim=0)"}, "line61": {"description": "Comment for line 61:     pos_embed_temporal = pos_embed_temporal[:, None, :]"}, "line62": {"description": "Comment for line 62:     pos_embed_temporal = pos_embed_temporal.repeat_interleave("}, "line63": {"description": "Comment for line 63:         spatial_size[0] * spatial_size[1], dim=1"}, "line64": {"description": "Comment for line 64:     )"}, "line65": {"description": "Comment for line 65:     pos_embed = torch.concat([pos_embed_temporal, pos_embed_spatial], dim=-1)"}, "line66": {"description": "Comment for line 66:     return pos_embed"}}\n```',
    },
    {
        "role": "assistant",
        "content": '{"line1": "", "line2": "", "line3": "", "line4": "", "line5": "", "line6": "", "line7": "", "line8": "", "line9": "", "line10": "", "line11": "", "line12": "", "line13": "", "line14": "", "line15": "Calculate exponent for sinusoidal embedding", "line16": "", "line17": "", "line18": "Adjust exponent based on the downscale frequency shift", "line19": "Calculate embedding using exponent", "line20": "Multiply timesteps with embedding", "line21": "Scale the embedding", "line22": "Concatenate sine and cosine of embedding", "line23": "Flip the order of sine and cosine if required", "line24": "", "line25": "Pad the embedding if embedding dimension is odd", "line26": "", "line27": "", "line28": "", "line29": "", "line30": "", "line31": "", "line32": "", "line33": "", "line34": "", "line35": "", "line36": "", "line37": "", "line38": "", "line39": "", "line40": "", "line41": "", "line42": "", "line43": "", "line44": "", "line45": "", "line46": "", "line47": "", "line48": "", "line49": "", "line50": "", "line51": "## 1. Spacial\\nCreate a grid for the height dimension", "line52": "Create a grid for the width dimension", "line53": "Create a meshgrid for spatial dimensions", "line54": "", "line55": "", "line56": "Get the spatial positional embedding", "line57": "## 2. Temporal\\nCreate a grid for the temporal dimension", "line58": "Get the temporal positional embedding", "line59": "## 3. Concatenate spacial and temporal embeddings\\nAdd a batch dimension to the spatial embedding", "line60": "Repeat the spatial embedding along the temporal dimension\\n[T, H*W, D // 4 * 3]", "line61": "Add a batch dimension to the temporal embedding", "line62": "Repeat the temporal embedding along the spatial dimension\\n[T, H*W, D // 4]", "line63": "", "line64": "", "line65": "[T, H*W, D]", "line66": ""}',
    },
    {
        "role": "user",
        "content": 'Input code:\n```\nimport time\n\nasync def fetch_user_profile(user_id: int) -> dict:\n\t"""\n   \tAsynchronously fetches a user profile from an API and returns it as a dictionary.\n\n   \tArgs:\n   \t\tuser_id (`int`):\n   \t\t\tThe ID of the user whose profile is to be fetched.\n\n   \tReturns:\n   \t\t`dict`: A dictionary containing the user\'s profile information, including:\n   \t\t\t- `id` (`int`): The user\'s ID.\n   \t\t\t- `name` (`str`): The user\'s name.\n   \t\t\t- `email` (`str`): The user\'s email address.\n   \t\t\t- `created_at` (`str`): The timestamp of when the user profile was created.\n   \t\t\t- `request_time` (`float`): The time taken to fetch the user profile in seconds.\n\t"""\n\tstart_time = time.time()\n\tasync with aiohttp.ClientSession() as session:\n\t\turl = f"https://api.example.com/users/{user_id}"\n\t\tresponse = await session.get(url)\n\t\tdata = await response.json()\n\n\tprofile = {\n\t\t"id": user_id,\n\t\t"name": data["name"],\n\t\t"email": data["email"],\n\t\t"created_at": data["created_at"],\n\t}\n\tprofile["request_time"] = time.time() - start_time\n\treturn profile\n```\n\nJson schema:\n```\n{"line1": {"description": "Comment for line 1: import time"}, "line2": {"description": "Comment for line 2: async def fetch_user_profile(user_id: int) -> dict:"}, "line3": {"description": "Comment for line 3: \\tstart_time = time.time()"}, "line4": {"description": "Comment for line 4: \\tasync with aiohttp.ClientSession() as session:"}, "line5": {"description": "Comment for line 5: \\t\\turl = f\\"https://api.example.com/users/{user_id}\\""}, "line6": {"description": "Comment for line 6: \\t\\tresponse = await session.get(url)"}, "line7": {"description": "Comment for line 7: \\t\\tdata = await response.json()"}, "line8": {"description": "Comment for line 8: \\tprofile = {"}, "line9": {"description": "Comment for line 9: \\t\\t\\"id\\": user_id,"}, "line10": {"description": "Comment for line 10: \\t\\t\\"name\\": data[\\"name\\"],"}, "line11": {"description": "Comment for line 11: \\t\\t\\"email\\": data[\\"email\\"],"}, "line12": {"description": "Comment for line 12: \\t\\t\\"created_at\\": data[\\"created_at\\"],"}, "line13": {"description": "Comment for line 13: \\t}"}, "line14": {"description": "Comment for line 14: \\tprofile[\\"request_time\\"] = time.time() - start_time"}, "line15": {"description": "Comment for line 15: \\treturn profile"}}\n```',
    },
    {
        "role": "assistant",
        "content": '{"line1": "", "line2": "", "line3": "", "line4": "", "line5": "", "line6": "Send a GET request to API to fetch user profile", "line7": "", "line8": "", "line9": "", "line10": "", "line11": "", "line12": "", "line13": "", "line14": "", "line15": ""}',
    },
    {
        "role": "user",
        "content": 'Input code:\n```\nimport ast\nfrom openai import Client\nfrom .components import add_docstrings, annotate_arguments, potentially_add_class_to_typing_import\nfrom .utils.utils import _get_nodes_dict_with_functions_classes_methods\n\ndef _check_no_duplicating_methods(nodes: list[ast.AST]) -> None:\n\t"""\n   \tChecks for duplicate function and class method names within a list of AST nodes. Raises a `ValueError` if any duplicates are found.\n\n   \tArgs:\n   \t\tnodes (`list[ast.AST]`):\n   \t\t\tA list of AST nodes to check for duplicate function and class method names.\n\n   \tReturns:\n   \t\tNone\n\n   \tRaises:\n   \t\tValueError: If any function or class method names are duplicated.\n\t"""\n\tfunctions_names = []\n\tclasses_names = []\n\tfor node in nodes:\n\t\tif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n\t\t\tfunctions_names.append(node.name)\n\t\telif isinstance(node, ast.ClassDef):\n\t\t\tclasses_names.append(node.name)\n\t\t\tclass_methods_names = []\n\t\t\tfor subnode in node.body:\n\t\t\t\tif isinstance(subnode, (ast.FunctionDef, ast.AsyncFunctionDef)):\n\t\t\t\t\tclass_methods_names.append(subnode.name)\n\t\t\t#methods\n\t\t\tif len(set(class_methods_names)) != len(class_methods_names):\n\t\t\t\tfor method in class_methods_names:\n\t\t\t\t\tif class_methods_names.count(method) != 1:\n\t\t\t\t\t\traise ValueError(\n\t\t\t\t\t\t\tf"Method {method} is duplicated for class {node.name}."\n\t\t\t\t\t\t\t+ "Please fix this before running annotation."\n\t\t\t\t\t\t)\n\n\t#functions\n\tif len(set(functions_names)) != len(functions_names):\n\t\tfor func in functions_names:\n\t\t\tif functions_names.count(func) != 1:\n\t\t\t\traise ValueError(\n\t\t\t\t\tf"Function {func} is duplicated."\n\t\t\t\t\t+ "Please fix this before running annotation."\n\t\t\t\t)\n    #classes\n\tif len(set(classes_names)) != len(classes_names):\n\t\tfor class_ in classes_names:\n\t\t\tif classes_names.count(class_) != 1:\n\t\t\t\traise ValueError(\n\t\t\t\t\tf"Class {class_} is duplicated."\n\t\t\t\t\t+ "Please fix this before running annotation."\n\t\t\t\t)\n\ndef document_python_code(\n\tcode: str,\n\tclient: Client,\n\tmodify_existing_annotation: bool = False,\n\tmodel_checkpoint: str = "Qwen/Qwen2.5-Coder-32B-Instruct-fast",\n) -> Generator[str, None, None]:\n\t"""\n\tGenerates and adds docstrings to Python code using an OpenAI client. The function processes the code to annotate arguments and add docstrings to functions, classes, and methods. It also ensures that necessary typing imports are included.\n\n\tArgs:\n\t\tcode (`str`):\n\t\t\tThe Python code as a string to which docstrings and argument annotations will be added.\n\t\tclient (`Client`):\n\t\t\tAn instance of the OpenAI client used to generate docstrings and annotations.\n\t\tmodify_existing_annotation (`bool`, *optional*, defaults to `False`):\n\t\t\tIf `True`, existing annotations and docstrings will be modified. If `False`, existing annotations and docstrings will be preserved unless they are empty.\n\t\tmodel_checkpoint (`str`, *optional*, defaults to `\'Qwen/Qwen2.5-Coder-32B-Instruct-fast\'`):\n\t\t\tThe model checkpoint to use for generating docstrings and annotations.\n\n\tYields:\n\t\t`str`: The updated code with added or modified docstrings and argument annotations.\n\n\tRaises:\n\t\t`SyntaxError`: If the generated code is not valid Python syntax.\n\t"""\n\tcode = rf"{code}" # read it raw to avoid ast errors\n\trequired_typing_imports = set()\n\tbody = ast.parse(code).body\n\n\t_check_no_duplicating_classes_methods_functions(body)\n\ttarget_nodes_dict = _get_nodes_dict_with_functions_classes_methods(body)\n\n\toutput = None\n\tfor output in annotate_arguments(\n\t\ttarget_nodes_dict=target_nodes_dict,\n\t\tcode=code,\n\t\tclient=client,\n\t\tmodify_existing_annotation=modify_existing_annotation,\n\t\tmodel_checkpoint=model_checkpoint,\n\t):\n\t\tif isinstance(output, str):\n\t\t\tyield output\n\t\tcode = output\n\tif isinstance(output, tuple):\n\t\tcode, func_required_typing_imports = output\n\t\trequired_typing_imports = required_typing_imports.union(\n\t\t\tfunc_required_typing_imports\n\t\t)\n\n\tcode = code.replace(" " * 4, "\t")\n\ttree = ast.parse(code)\n\ttarget_nodes_dict = _get_nodes_dict_with_functions_classes_methods(tree.body)\n\n\tfor output in add_docstrings(\n\t\ttarget_nodes_dict=target_nodes_dict,\n\t\tcode=code,\n\t\tclient=client,\n\t\tmodify_existing_annotation=modify_existing_annotation,\n\t\tmodel_checkpoint=model_checkpoint,\n\t):\n\t\tyield output\n\t\tcode = output\n\t# Add classes from typing that were not imported\n\tfor typing_class in required_typing_imports:\n\t\tcode = potentially_add_class_to_typing_import(code, tree, typing_class)\n\t\tyield code\n\tcode = code.replace(" " * 4, "\t")\n\tast.parse(code) # to check it is valid\n\tyield code\n```\n\nJson schema:\n```\n{"line1": {"description": "Comment for line 1: import ast"}, "line2": {"description": "Comment for line 2: from openai import Client"}, "line3": {"description": "Comment for line 3: from .components import add_docstrings, annotate_arguments, potentially_add_class_to_typing_import"}, "line4": {"description": "Comment for line 4: from .utils.utils import _get_nodes_dict_with_functions_classes_methods"}, "line5": {"description": "Comment for line 5: def _check_no_duplicating_methods(nodes: list[ast.AST]) -> None:"}, "line6": {"description": "Comment for line 6: \\tfunctions_names = []"}, "line7": {"description": "Comment for line 7: \\tclasses_names = []"}, "line8": {"description": "Comment for line 8: \\tfor node in nodes:"}, "line9": {"description": "Comment for line 9: \\t\\tif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):"}, "line10": {"description": "Comment for line 10: \\t\\t\\tfunctions_names.append(node.name)"}, "line11": {"description": "Comment for line 11: \\t\\telif isinstance(node, ast.ClassDef):"}, "line12": {"description": "Comment for line 12: \\t\\t\\tclasses_names.append(node.name)"}, "line13": {"description": "Comment for line 13: \\t\\t\\tclass_methods_names = []"}, "line14": {"description": "Comment for line 14: \\t\\t\\tfor subnode in node.body:"}, "line15": {"description": "Comment for line 15: \\t\\t\\t\\tif isinstance(subnode, (ast.FunctionDef, ast.AsyncFunctionDef)):"}, "line16": {"description": "Comment for line 16: \\t\\t\\t\\t\\tclass_methods_names.append(subnode.name)"}, "line17": {"default": "methods", "description": "Comment for line 17: \\t\\t\\tif len(set(class_methods_names)) != len(class_methods_names):"}, "line18": {"description": "Comment for line 18: \\t\\t\\t\\tfor method in class_methods_names:"}, "line19": {"description": "Comment for line 19: \\t\\t\\t\\t\\tif class_methods_names.count(method) != 1:"}, "line20": {"description": "Comment for line 20: \\t\\t\\t\\t\\t\\traise ValueError("}, "line21": {"description": "Comment for line 21: \\t\\t\\t\\t\\t\\t\\tf\\"Method {method} is duplicated for class {node.name}.\\""}, "line22": {"description": "Comment for line 22: \\t\\t\\t\\t\\t\\t\\t+ \\"Please fix this before running annotation.\\""}, "line23": {"description": "Comment for line 23: \\t\\t\\t\\t\\t\\t)"}, "line24": {"default": "functions", "description": "Comment for line 24: \\tif len(set(functions_names)) != len(functions_names):"}, "line25": {"description": "Comment for line 25: \\t\\tfor func in functions_names:"}, "line26": {"description": "Comment for line 26: \\t\\t\\tif functions_names.count(func) != 1:"}, "line27": {"description": "Comment for line 27: \\t\\t\\t\\traise ValueError("}, "line28": {"description": "Comment for line 28: \\t\\t\\t\\t\\tf\\"Function {func} is duplicated.\\""}, "line29": {"description": "Comment for line 29: \\t\\t\\t\\t\\t+ \\"Please fix this before running annotation.\\""}, "line30": {"description": "Comment for line 30: \\t\\t\\t\\t)"}, "line31": {"default": "classes", "description": "Comment for line 31: \\tif len(set(classes_names)) != len(classes_names):"}, "line32": {"description": "Comment for line 32: \\t\\tfor class_ in classes_names:"}, "line33": {"description": "Comment for line 33: \\t\\t\\tif classes_names.count(class_) != 1:"}, "line34": {"description": "Comment for line 34: \\t\\t\\t\\traise ValueError("}, "line35": {"description": "Comment for line 35: \\t\\t\\t\\t\\tf\\"Class {class_} is duplicated.\\""}, "line36": {"description": "Comment for line 36: \\t\\t\\t\\t\\t+ \\"Please fix this before running annotation.\\""}, "line37": {"description": "Comment for line 37: \\t\\t\\t\\t)"}, "line38": {"description": "Comment for line 38: def document_python_code("}, "line39": {"description": "Comment for line 39: \\tcode: str,"}, "line40": {"description": "Comment for line 40: \\tclient: Client,"}, "line41": {"description": "Comment for line 41: \\tmodify_existing_annotation: bool = False,"}, "line42": {"description": "Comment for line 42: \\tmodel_checkpoint: str = \\"Qwen/Qwen2.5-Coder-32B-Instruct-fast\\","}, "line43": {"description": "Comment for line 43: ) -> Generator[str, None, None]:"}, "line44": {"default": "read it raw to avoid ast errors", "description": "Comment for line 44: \\tcode = rf\\"{code}\\""}, "line45": {"description": "Comment for line 45: \\trequired_typing_imports = set()"}, "line46": {"description": "Comment for line 46: \\tbody = ast.parse(code).body"}, "line47": {"description": "Comment for line 47: \\t_check_no_duplicating_classes_methods_functions(body)"}, "line48": {"description": "Comment for line 48: \\ttarget_nodes_dict = _get_nodes_dict_with_functions_classes_methods(body)"}, "line49": {"description": "Comment for line 49: \\toutput = None"}, "line50": {"description": "Comment for line 50: \\tfor output in annotate_arguments("}, "line51": {"description": "Comment for line 51: \\t\\ttarget_nodes_dict=target_nodes_dict,"}, "line52": {"description": "Comment for line 52: \\t\\tcode=code,"}, "line53": {"description": "Comment for line 53: \\t\\tclient=client,"}, "line54": {"description": "Comment for line 54: \\t\\tmodify_existing_annotation=modify_existing_annotation,"}, "line55": {"description": "Comment for line 55: \\t\\tmodel_checkpoint=model_checkpoint,"}, "line56": {"description": "Comment for line 56: \\t):"}, "line57": {"description": "Comment for line 57: \\t\\tif isinstance(output, str):"}, "line58": {"description": "Comment for line 58: \\t\\t\\tyield output"}, "line59": {"description": "Comment for line 59: \\t\\tcode = output"}, "line60": {"description": "Comment for line 60: \\tif isinstance(output, tuple):"}, "line61": {"description": "Comment for line 61: \\t\\tcode, func_required_typing_imports = output"}, "line62": {"description": "Comment for line 62: \\t\\trequired_typing_imports = required_typing_imports.union("}, "line63": {"description": "Comment for line 63: \\t\\t\\tfunc_required_typing_imports"}, "line64": {"description": "Comment for line 64: \\t\\t)"}, "line65": {"description": "Comment for line 65: \\tcode = code.replace(\\" \\" * 4, \\"\\t\\")"}, "line66": {"description": "Comment for line 66: \\ttree = ast.parse(code)"}, "line67": {"description": "Comment for line 67: \\ttarget_nodes_dict = _get_nodes_dict_with_functions_classes_methods(tree.body)"}, "line68": {"description": "Comment for line 68: \\tfor output in add_docstrings("}, "line69": {"description": "Comment for line 69: \\t\\ttarget_nodes_dict=target_nodes_dict,"}, "line70": {"description": "Comment for line 70: \\t\\tcode=code,"}, "line71": {"description": "Comment for line 71: \\t\\tclient=client,"}, "line72": {"description": "Comment for line 72: \\t\\tmodify_existing_annotation=modify_existing_annotation,"}, "line73": {"description": "Comment for line 73: \\t\\tmodel_checkpoint=model_checkpoint,"}, "line74": {"description": "Comment for line 74: \\t):"}, "line75": {"description": "Comment for line 75: \\t\\tyield output"}, "line76": {"description": "Comment for line 76: \\t\\tcode = output"}, "line77": {"default": "Add classes from typing that were not imported", "description": "Comment for line 77: \\tfor typing_class in required_typing_imports:"}, "line78": {"description": "Comment for line 78: \\t\\tcode = potentially_add_class_to_typing_import(code, tree, typing_class)"}, "line79": {"description": "Comment for line 79: \\t\\tyield code"}, "line80": {"description": "Comment for line 80: \\tcode = code.replace(\\" \\" * 4, \\"\\t\\")"}, "line81": {"default": "to check it is valid", "description": "Comment for line 81: \\tast.parse(code)"}, "line82": {"description": "Comment for line 82: \\tyield code"}}\n```',
    },
    {
        "role": "assistant",
        "content": '{"line1": "", "line2": "", "line3": "", "line4": "", "line5": "", "line6": "", "line7": "", "line8": "", "line9": "", "line10": "", "line11": "", "line12": "", "line13": "", "line14": "", "line15": "", "line16": "", "line17": "Check for duplicate method names within the class", "line18": "", "line19": "Check if the method name appears more than once", "line20": "", "line21": "", "line22": "", "line23": "", "line24": "Check for duplicate function names", "line25": "", "line26": "Check if the function name appears more than once", "line27": "", "line28": "", "line29": "", "line30": "", "line31": "Check for duplicate class names", "line32": "", "line33": "Check if the class name appears more than once", "line34": "", "line35": "", "line36": "", "line37": "", "line38": "", "line39": "", "line40": "", "line41": "", "line42": "", "line43": "", "line44": "Read the code as a raw string to avoid AST parsing errors", "line45": "", "line46": "Parse the code into an AST", "line47": "", "line48": "Get a dictionary of nodes that need to be annotated or documented", "line49": "Annotate the arguments of functions, classes, and methods", "line50": "", "line51": "", "line52": "", "line53": "", "line54": "", "line55": "", "line56": "", "line57": "", "line58": "", "line59": "", "line60": "", "line61": "Get the required imports from the `typing` package that will need to be added in the end", "line62": "", "line63": "", "line64": "", "line65": "Replace spaces with tabs for consistent formatting", "line66": "Lines may have changed, so it\'s easier to rerun `ast.parse` which takes < 1ms than track\\nthis throughout the code", "line67": "Get dictionary with target nodes with the updated AST code", "line68": "Add docstrings to functions, classes, and methods", "line69": "", "line70": "", "line71": "", "line72": "", "line73": "", "line74": "", "line75": "", "line76": "", "line77": "If annotation-related classes from the typing module are missing,\\nadd them to the imports", "line78": "", "line79": "", "line80": "Replace spaces with tabs for consistent formatting", "line81": "Parse the code to ensure it is valid Python syntax", "line82": ""}',
    },
]

MESSAGES_FIX_ANNOTATION = [
    {
        "role": "system",
        "content": 'Act as an experienced Python specialist.\n\nYou will be provided with a "broken" argument annotation in Python, which was written by our junior developer. Kindly fix this annotation. Output only the fixed annotation and nothing more. Your output will be directly inserted into the code and parsed with `ast`, so don\'t output anything else besides tha fixed annotation.',
    },
    {"role": "user", "content": "Union[str, List[Union[int, str, List[Any]]]"},
    {"role": "assistant", "content": "Union[str, List[Union[int, str, List[Any]]]]"},
    {
        "role": "user",
        "content": "tuple[ type[BaseModel], dict[ str, tuple[ Union[ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef], dict[ str, tuple[ Union[ast.arg, ast.AnnAssign, ast.Assign, ast.Constant, None], str | None, ] | tuple[Union[ast.arg, ast.AnnAssign, ast.Assign], str | None, str]",
    },
    {
        "role": "assistant",
        "content": "tuple[ type[BaseModel], dict[ str, tuple[ Union[ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef], dict[ str, tuple[ Union[ast.arg, ast.AnnAssign, ast.Assign, ast.Constant, None], str | None, ] | tuple[Union[ast.arg, ast.AnnAssign, ast.Assign], str | None, str]]]]]",
    },
    {"role": "user", "content": "integer"},
    {"role": "assistant", "content": "int"},
]
